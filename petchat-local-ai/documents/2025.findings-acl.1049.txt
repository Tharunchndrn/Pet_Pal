Localizing and Mitigating Errors in Long-form Question Answering

Rachneet Sachdeva♠, Yixiao Song♥, Mohit Iyyer♥, Iryna Gurevych♠

♠Ubiquitous Knowledge Processing Lab (UKP Lab),
Department of Computer Science and Hessian Center for AI (hessian.AI),

Technical University of Darmstadt
♥University of Massachusetts Amherst
www.ukp.tu-darmstadt.de

Abstract
GPT-4

Q: Can anyone Q: Can anyone explain 
explain the Question Q the differences […]

Long-form question answering (LFQA) aims differences between A: A trademark protects 
copyright and a brand's symbol or 

to provide thorough and in-depth answers to trademark? logo. A copyright 
A:  A trademark Answer M protects content. [...]

complex questions, enhancing comprehension. protects a brand's M: Copyright and 
symbol or logo. A trademark are both 

However, such detailed responses are prone to copyright protects QA pair Annotation legal protections for 
content. [...] intellectual property, 

hallucinations and factual inconsistencies, chal- but they [...]

Domain Experts
lenging their faithful evaluation. This work Highlight reason:

• Completeness

introduces HaluQuestQA, the first hallucina- • Answer A is 
Evaluation Criteria (span level)

incomplete because 

tion dataset with localized error annotations for The answer fails to 
mention the broader 

human-written and model-generated LFQA an- scope of  copyright 

Question protection, which 

swers. HaluQuestQA comprises 698 QA pairs Factuality Relevance includes creative 
Misconception

works beyond just 

with 1.8k span-level error annotations for five music and lyrics. 

different error types by expert annotators, along  Preferred Answer: M
Reason: […]

with preference judgments. Using our collected Completeness References

data, we thoroughly analyze the shortcomings
of long-form answers and find that they lack
comprehensiveness and provide unhelpful ref- Figure 1: Overview of our data collection process. Us-
erences. We train an automatic feedback model ing five fine-grained evaluation criteria, we collect span-
on this dataset that predicts error spans with in- level expert human judgments on question-answer pairs
complete information and provides associated from the Reddit platform, as well as on corresponding
explanations. Finally, we propose a prompt- answers generated by GPT-4.
based approach, Error-Informed Refinement,
that uses signals from the learned feedback Traditional evaluation metrics of answer qual-
model to refine generated answers, which we ity, such as BLEU (Papineni et al., 2002),
show reduces errors and improves the quality ROUGE (Lin, 2004), and BERTScore (Zhang et al.,
of the answers across multiple models. Further- 2020) yield only a single score, obscuring the er-
more, humans find the answers generated by
our approach comprehensive and highly prefer ror type, severity, and location in the answer. We
them (84%) over the baseline answers.1 take inspiration from machine translation, which

moved beyond this simplistic evaluation paradigm
1 Introduction by localizing and categorizing errors (Freitag et al.,

2021; Kocmi et al., 2024), resulting in higher-
Long-form question answering (LFQA) provides quality and more interpretable evaluations. We
comprehensive, user-friendly, and in-depth re- make a similar contribution to the field of LFQA
sponses to complex questions by leveraging state- by asking human annotators to identify spans from
of-the-art large language models (LLMs) and re- the answers that correspond to errors and catego-
triever components (Krishna et al., 2021; Nakano rize each span into an error schema that we design.
et al., 2021). While LLMs generate plausible and Our work is the first to explore error localization in
convincing answers, they also hallucinate and pro- LFQA, offering a more detailed and interpretable
duce factually inconsistent, irrelevant, and incom- evaluation of answers.
plete content (Goyal and Durrett, 2020; Laban et al., LLMs make many errors for LFQA that require
2022; Menick et al., 2022; Ji et al., 2022), which are targeted evaluation. Xu et al. (2023a) highlight
difficult to detect for both humans and machines. that key aspects such as factuality, relevance, com-

1Code and data available at: github.com/lfqa-errors pleteness, structure, references, and accessibility

20437
Findings of the Association for Computational Linguistics: ACL 2025, pages 20437–20469

July 27 - August 1, 2025 ©2025 Association for Computational Linguistics



are essential to evaluate long-form answers. Other 2 Related Work
recent studies have also validated the importance of Human evaluation. Prior work (Krishna et al.,
aspects such as question misconception (Krishna 2021) has shown that human evaluation for LFQA
et al., 2021), factuality (Wu et al., 2023b; Jiang tasks is challenging due to long answer lengths,
et al., 2023b; Wang et al., 2024b), relevance (Tang and expert annotators are required to evaluate them
et al., 2024), and completeness (Samarinas et al., effectively. Xu et al. (2023a) hire expert annotators
2025) in determining answer quality. While prior and identify nine multi-faceted aspects for mean-
work has mainly focused on evaluating factual- ingful LFQA evaluation. While some of these fine-
ity (Lee et al., 2022; Min et al., 2023; Li et al., grained aspects, such as factuality (Goyal and Dur-
2023; Muhlgay et al., 2023) and faithfulness (Su rett, 2020; Laban et al., 2022), coherence (Goyal
et al., 2022) in long-form text generation, other et al., 2022), and completeness (Tang et al., 2024),
aspects of evaluation, such as response complete- have been used to investigate errors in summariza-
ness and relevance (which can particularly mislead tion tasks, ours is amongst the first works to study
users), have received less attention. LFQA-centric errors at the span level. To this end,

Our work addresses this gap by introducing we collect span-level annotations of LFQA errors,
HaluQuestQA, a dataset of long-form answers an- enabling high-quality and interpretable evaluations
notated at the span level with five error types: ques- that can be used to improve answer quality. While
tion misconception, factuality, completeness, rele- this has been done for machine translation (Freitag
vance, and references. Expert annotators provide et al., 2021; Kocmi et al., 2024), it has not yet been
these annotations and preference judgments, as applied to long-form question answering.
shown in Figure 1. Automatic evaluation. Increasing focus on the

Next, we train an automatic feedback model on reliability of LLMs has led to the development of
this dataset to predict erroneous answer spans that explainable evaluation metrics (Zhong et al., 2022;
lack key details to address the question comprehen- Fu et al., 2023) to detect errors in LLM gener-
sively. The feedback model provides fine-grained ations. Xu et al. (2023b) present InstructScore,
feedback, identifying error locations (sentence an explainable metric based on LLaMA (Touvron
level), error justification, and a confidence score, et al., 2023a), to obtain detailed error analysis for
all without relying on reference texts (Xu et al., LLM-generated text. However, most of the current
2023b). Finally, we propose ERROR-INFORMED evaluation metrics require hard-to-obtain gold refer-
REFINEMENT, a prompt-based approach that uses ences. Jiang et al. (2023b) propose a reference-free
signals from the feedback model to refine generated evaluation metric, TIGERSCORE, that can locate,
answers (Madaan et al., 2023), reducing errors and categorize, and explain errors across various text
improving answer quality across multiple LLMs. generation tasks, including LFQA. While LLM-
Our contributions are summarized as follows: based metrics can detect diverse errors, they are

prone to hallucinations due to training data qual-
• We release HaluQuestQA, a dataset with span- ity. In this study, we collect expert-annotated data

level error annotations on pairs of human-written on fine-grained LFQA errors and train a feedback
and model-generated answers. Our analysis re- model for accurate error detection.
veals that long-form answers often lack compre-
hensiveness and provide unhelpful references. Mitigating errors with human feedback.

Reinforcement learning with human feed-
• We train a feedback model to identify erro- back (RLHF) (Ziegler et al., 2019) incorporates

neous answer spans with incomplete informa- human feedback to train reward models and align
tion, aligned with expert human judgments. Al- LLMs, reducing undesirable generations (Ouyang
though our dataset encompasses multiple errors, et al., 2022; Bai et al., 2022a,b; Wu et al., 2023b).
our feedback model focuses on completeness er- A recent alignment technique, direct preference op-
rors, which are identified as the most critical issue timization (DPO) (Rafailov et al., 2023), bypasses
in the LFQA answers. the computationally expensive reward modeling

• We propose Error-Informed Refinement, an ap- step and has been used to fine-tune LMs for
proach that applies fine-grained feedback from factuality (Tian et al., 2023). Human feedback has
our learned model to improve the quality of also been used to fine-tune feedback models (Wang
human-written and LLM-generated answers. et al., 2023; Xu et al., 2024) to guide the refinement

20438



Category Preference Krippendorf’s 3.2 Task Setup
(# samples) 𝛼

Human Model We evaluate two answers (human and model-
Physics (94) 33% 67% 0.01 generated) to the same questions. This setting
Chemistry (96) 22% 78% 0.20
Biology (110) 25% 75% 0.36 enables us to identify errors made by humans
Technology (110) 16% 84% 0.53 and state-of-the-art LFQA systems. We chose
Economics (110) 14% 86% 0.31
History (92) 9% 91% 0.52 GPT-4 (gpt-4-0314) as the LFQA model to
Law (86) 16% 84% 0.59 evaluate since previous work (Bhat et al., 2023)
Average 19.29% 80.71% 0.36 has shown it outperforming existing open-source

LLMs (LLaMA and Alpaca (Taori et al., 2023)) in
Table 1: Overview of HaluQuestQA and expert answer reasoning and inferring from long context. Since
preferences, with experts’ agreement on a smaller sub-
set (~15%) calculated using Krippendorf’s alpha (Hayes GPT-4’s training data extends up to September
and Krippendorff, 2007) (Appendix A.5). 2021, it may have already seen the ELI5 dataset

released by Fan et al. (2019) during its pre-training.
Thus, we scrape more recent questions with their

of LLM outputs (Madaan et al., 2023; Welleck highest-voted answers from the r/explainlikeimfive
et al., 2023; Ji et al., 2023), improving answer subreddits posted between November 2022 and
quality. However, these feedback models either March 2023, following Xu et al. (2023a). We pro-
lack fine-grained error feedback or depend on vide further details of the setup in Appendix A.
ground truth passages, which may not always be To obtain the model-generated answers, we zero-
available in open-domain QA. In our study, we shot prompt the GPT-4 model (Appendix B.1). We
develop a reference-free feedback model to refine host the annotation task on the INCEpTION plat-
LFQA answers with detailed error feedback. form (Klie et al., 2018) and evaluate the following:2

1. Question misconception: False assumptions
3 HaluQuestQA (HQ2A) made within the given question.

Prior LFQA evaluations with non-expert (Nakano 2. Factuality: Accuracy and correctness of the
et al., 2021) and expert (Xu et al., 2023a) annotators answer as per verifiable facts.
collect preference judgments over model responses. 3. Relevance: Specificity and meaningfulness of
However, overall preference is not indicative of the answer.
fine-grained errors in LFQA. As a first step, we 4. Completeness: Answer comprehensiveness en-
annotate span-level errors in long-form answers, suring all question aspects are addressed.
with explanations from domain experts.

5. References: (Un)helpful examples, analogies,

3.1 Hiring Annotators and external links in the answer.
Annotators highlight errors in questions or answers

We recruit domain experts on Prolific’s academic based on evaluation criteria, provide free-form jus-
annotation platform for seven domains shown in Ta- tifications, and indicate overall answer preferences.
ble 1. The expert selection is based on age (22-32), 3.3 Data Curation
demographics (US and UK), education (undergrad-
uate or graduate degree in the target domain), and To ensure high-quality annotations, we implement
native language (English). For each target domain, several checks before, during, and after the annota-
we first conduct a small pilot comprising ten sam- tion process. Before annotation, we ensure the qual-
ples, where given a question and two candidate an- ity of scraped questions by removing duplicates,
swers, the experts evaluate the answers and mark all discarding questions under five words, and verify-
erroneous or problematic parts (phrase, sentence, ing grammar and fluency. For the corresponding
or multiple sentences) based on our defined evalua- answers, we select responses that receive the high-
tion criteria (§3.2). After carefully evaluating the est upvotes on Reddit and have a minimum length
pilot results for relevance, clarity, and factuality, of 50 words. We also verify that the responses are
we choose three experts per domain and give them not generated by AI-assisted tools (e.g., ChatGPT3)
each a large-scale study containing 35-50 QA pairs. 2We provide detailed annotation guidelines in Appendix F.
We collect expert judgments for 698 questions. 3https://chat.openai.com

20439



Aspect Question Answer A Answer B Expert Justification
How do people in (human) [...] While prison food gen- (model) [...] In prison, inmates often This is an assumption, not every

Question prison get so jacked erally doesn’t taste great, it does have a lot of free time, which they prison offers terrible food without
Misconception with terrible nutrition have calories and protein. [...] can can use to work out and develop a nutritional value, also lots of "easy"

and no supplements? buy on commissary (fish [...] consistent exercise routine. [...] food choices (lentils, eggs, [...]

What is difficult about (human) The main problem is the (model) Developing nuclear The claim is false. According to
Factuality developing nuclear nuclear fuel [...] Uranium is a fairly weapons is a highly complex and the World Nuclear Association, Ura-

weapons that makes rare element on its own, but to make resource-intensive [...] To create a nium is not a rare element and oc-
some countries inca- a bomb you need lots of a very rare nuclear bomb, a nation must have a curs in potentially recoverable con-
pable of making them? isotope of uranium (u-235) [...] deep understanding of [...] centrations in many types [...]

Why is it taboo to talk (human) Because companies used (model) Talking about wages is con- This does not contribute to the an-
about people’s wages? to be able to fire [...] discussing your sidered taboo because it can create swer.

Relevance wages is a federally [...] so by all tension and jealousy [...]. Employ-
means discuss discuss discuss! [...] ers often discourage discussions [...]

Can anyone explain (human) A trademark protects a (model) [...] Copyright protects cre- The answer fails to mention the
Completeness the differences between brand’s symbol or logo. A copy- ative works like books, music, and broader scope of copyright protec-

copyright and trade- right protects content. So the ac/dc art, [...]. Trademark, on the other tion, which includes creative works
mark? logo with the lightning bolt [...] hand, protects brand identifiers [...] beyond just music and lyrics.

Why is 1000mbps in- (human) [...] It’s similar to asking (model) Internet speeds are often ad- The example is terrible and does not
ternet only guaranteed why postal mail weighs more than vertised as "up to" a certain speed give any idea of what the writer is
at 900mbps and what’s just the paper you are sending... Ev- because various factors can affect talking about.

References the equipment needed erything that tells it how to get to the the actual performance. For in-
to get the 1000mbps ad- other side encapsulates (contains) it, stance, network congestion... To get
vertised? and makes up that extra weight. the full 1000mbps advertised, [...]

Table 2: Examples of expert annotated errors in long-form answers based on the defined evaluation criteria. The
answers in green are expert-preferred answers. Additional examples are provided in Table 13 in the Appendix.

using a commercial AI detector (GPTZero4). We attributed to its ability to learn facts that remain
find that none of the responses are flagged as AI- consistent over time, during its training process.
generated, though we acknowledge the inherent However, it struggles with college-level scientific
limitations of AI detection tools. During anno- questions requiring advanced reasoning (Sun et al.,
tation, annotators are encouraged to contact the 2024; Wang et al., 2024a) – and our dataset in-
authors anonymously through Prolific for clarifica- cludes complex, real-world scientific problems that
tion to reduce potential errors. After the study, we surpass college-level difficulty, likely contributing
manually review error spans, justifications, refer- to its lower performance in scientific domains.
ences, and preference judgments, verifying their
quality and ensuring no AI involvement. Iterative 3.5 Fine-grained Answer Scoring
feedback and bonus payments further incentivize We score human and model answers on our defined
high-quality work. Examples are shown in Table 2. evaluation criteria to understand how experts’ an-
3.4 Quantitative Analysis swer preferences diverge across different domains.

For the question misconception aspect, the score
As shown in Table 1, experts display a high pref- S = 1 when the question has no misconceptions;
erence (80.7%) for GPT-4 answers compared to otherwise, S = 0. For aspects of factuality, rele-
human answers. We hypothesize that humans pre- )

vance, and completeness, S = 1− ( # Error sentences ,
fer fluent answers, and LLMs are known to op- whil( Total # of sentences

e the score for r)eference is calculated as S =
timize for fluency (Wu et al., 2023a; Coyne and

1 − # Error references
Total # of references .

Sakaguchi, 2023). Moreover, the preference of our
annotators is corroborated by similar findings in For calculating the overall answer scores, we leave
summarization (Liu et al., 2023b) and LFQA (Xu out the question misconception scores because this
et al., 2023a), who show that GPT-3 answers score aspect pertains to the question. We sum the other
higher than human answers. aspect scores and include the overall answer pref-

Comparing different domains, we observe that erence scores (S = 1 if preferred) to get the final
experts strongly prefer GPT-4 answers in history, score. Finally, we normalize this score between
law, technology, and economics (>80%). However, 0 and 1. In Figure 2, we report the fine-grained
in science domains like physics, biology, and chem- aspect scores for human and model answers across
istry, model preference drops to 60-80%. GPT- different domains and discuss our findings below.
4’s strong performance in history and law can be 1) Questions from technology and economics are

4https://app.gptzero.me/ biased. Ambiguous and misinformed questions

20440



Human Model a crucial role in their higher preference.
Question Misconception Factuality

1 4 Error Mitigation
0.5

In §3.4, we have shown that the LFQA answers lack
0 completeness and omit useful information. There-

Relevance Completeness
1 fore, we train a feedback model to identify erro-

neous answer spans with incomplete information
0.5

and provide free-form error justifications. Our ap-
0 proach ERROR-INFORMED REFINEMENT, uses this

References Overall
1 feedback to refine the answers and improve their

overall quality without human intervention.
0.5

0 4.1 Error Feedback Model
sics stry gy gy ics ry law y

phy iolo ysics cs y Given an input question and an LFQA response,
chemi b nolo histo ph mistryb ology

i olog
tech econom

che nomi
histo

r law
techn

eco
we fine-tune the LLaMA2-13B model (Touvron

Figure 2: Comparison of fine-grained scores of the et al., 2023b) to generate a label [Complete] or [In-
human-written and model-generated answers for differ- complete] for every sentence 1...𝑛 in the response
ent evaluation criteria. The last figure (with red bound- and provide associated reasons for the incomplete
ary) shows the averaged and normalized overall scores.
A higher score represents fewer errors in the answers. sentences (see Figure 3).

Dataset & Training. Training the feedback
can lead to undesirable answers (Cole et al., 2023; model requires high-quality error annotations with
Kim et al., 2023). Therefore, fair answer scoring justifications. To support this, we extract QA
requires prior estimation of question quality. For pairs with annotated completeness errors from our
this, we utilize the question misconception aspect dataset, which includes both sentence- and phrase-
and find that questions from all evaluated domains level annotations. Since ~65% of annotated com-
consist of misconceptions arising from the user’s pleteness errors occur at the sentence level (see
bias or misinformation. This is especially promi- Table 6), we adopt sentence-level granularity as
nent in technology and economics, where ~40% both representative and practical for training and
of the questions are misinformed – users have low evaluating our feedback model. To facilitate this,
domain knowledge to ask the right questions. Thus, we convert phrase-level errors to sentence-level an-
we encourage future research to assess the capabil- notations by assigning the phrase’s error label and
ity of LLMs to rebut misconceived questions. justification to its containing sentence. Further-

more, in cases where annotators mark the entire
2) Answers lack comprehensiveness and provide answer as incomplete (Appendix F.2), we assign
unhelpful references. We observe that human- the same error label and justification to each sen-
written and model-generated answers score high on tence in the answer. We provide illustrative exam-
factuality and relevance, meaning most of the infor- ples of sentence-level annotations in Table 12 in
mation provided is verifiable, trustworthy and rele- the Appendix.
vant to the question. However, the answers score Finally, after preprocessing, we segment each
low on completeness and references aspects, lack- human- or model-generated answer into sentences
ing important information and providing web refer- and label each sentence as [Complete] or [Incom-
ences and examples that are not helpful (Liu et al., plete], with the corresponding expert-provided jus-
2023a), according to expert judgments. Specifi- tification. The final dataset consists of 509 sam-
cally, GPT-4 hallucinates and provides incorrect or ples with a 90/10 train/test split. Fine-tuning on
fabricated web links, while human answers digress this dataset is essential for accurate error feedback
from the topic and include irrelevant information. generation, as general-purpose LLMs used in a

Overall, GPT-4 answers score better than the zero-shot setting are not well-suited to detecting
human answers in all evaluated domains. While completeness errors (§5.1). We provide the training
this is due to its better performance over humans details in Appendix B.2.
in the considered aspects, the persuasive nature of Inference. The trained feedback model halluci-
the model responses (Salvi et al., 2024) also plays nates web references in about 20% of test sam-

20441

Aspect Score



Q: Consistency score (𝑆𝑅𝐶 ): 0.8 Refined Answer
Why are railroads full of

rocks? Prediction (Sentence-level): Railroads are full of rocks be-
A: Ballast is a comparably cheap 1. [Incomplete] Reasons: This is cause ballast provides an econom-
way of leveling ground that can correct; ballast is cheap and effec- ical and efficient solution for lev-
support a lot of weight very Feedback tive [...]. However, I think it will be Refine eling ground and preventing ero-
cheaply. Rocks don’t wash or Model useful to mention that ballast also
blow away [...]. Compared to say E helps with drainage and prevents Model sion. Additional benefits include

thermal cycling, self-leveling, and
erosion. R

a concrete foundation, they won’t ease of repair. [...] Here are some
crack or require formwork [...] 2. [Complete] reasons [...] 1. Cost effective [...]

3. [Complete] 2. Drainage [...] 3. Thermal [...]

Figure 3: A pictorial view of our Error-Informed Refinement approach. The FEEDBACK model takes a question-
answer pair as input and outputs sentence-level error with justifications and a consistency score. The REFINE model
uses this feedback to improve the original answer. Additional refined examples are in Table 14 (Appendix).

ples. This likely occurs because the training data 𝑗𝑠 and 0 if not. Finally, we select the highest scor-
includes web references in expert error justifica- ing output as feedback for the refinement model.
tions, which the model struggles to replicate coher- After sampling, reference hallucinations reduce
ently. To combat this, we opt for a sampling-based by 50% (from 20% to ~10% of the test set).
approach (Malon and Zhu, 2024) to provide more
consistent feedback. The intuition is that trustwor- 4.2 Error-Informed Refinement (EIR)
thy details and references should appear in many Our approach is shown in Figure 3 and con-
other generated samples. Hence, during the decod- sists of two main components: an error feedback
ing step, we sample 20 responses from the feedback model (§4.1), and a refinement model. Given
model and check their consistency in two stages: an input prompt 𝑥𝑖 and a corresponding human-
(1) TAG CONSISTENCY: This pertains to the con- written or model-generated response 𝑦𝑖, the feed-
sistency of span-level tag predictions, complete back model E generates a targeted feedback 𝑓𝑖 that
or incomplete, for each sampled response. The represents the quality of 𝑦𝑖 in free-form natural lan-
tag consistency score is calculated by counting the guage. Finally, the refinement model R uses 𝑥𝑖 , 𝑦𝑖 ,
number of other sampled responses that match the and 𝑓𝑖 to generate a refined and improved output
tag sequence of each sampled output and averaging 𝑦𝑖 . The following sections describe our approach.
over the total number of samples. Formally, if the
sampled tag predictions 𝑝1, ..., 𝑝𝑛 consist of tag se- Refinement Model & Baselines. Our experi-
quences 𝑡1, ..., 𝑡𝑛 where 𝑡𝑖 is a list of tag predictions ments use the LLaMA2-13B chat LLM and its
for every span, the score for sample 𝑖 is DPO optimized version (see Appendix C) as the

refinement model. In each case, the model is 0-
𝑛

S 1 ∑︁ shot prompted with the fine-grained error feedback
TC = 1𝑡 =

𝑛 𝑖 𝑡𝑠
𝑠=1 received from the error detection model. We also

experiment with two strong baseline feedback mod-
where 1𝑡𝑖=𝑡𝑠 is 1 if the tag sequence 𝑡𝑖 is the same els, (1) IMPROVE: The refinement model is 0-shot
as tag sequence 𝑡𝑠 and 0 if not. The samples with prompted to improve the answer without any error
the highest score are selected for the next stage. feedback provided. (2) GENERIC: The refinement
(2) REASON CONSISTENCY: We assess the con- model is 0-shot prompted to improve the answer
sistency of justifications given for the incomplete with a generic error feedback that asks the model
spans from the remaining samples. Specifically, to provide a more complete and accurate answer.
we count the number of other sampled justifica- We list the prompts used in Appendix B.3.
tions from the LLM that matched each token of
each sampled output and score each justification Datasets & Evaluation Metrics. We test our
by the average count per token. Formally, if the error-informed refinement approach on three
sampled justifications 𝑗1, ..., 𝑗𝑛 consist of words datasets: HQ2A with span-level error annotations
𝑤𝑘
𝑖 , 𝑘 = 1...𝑚𝑖 , the score of sample 𝑖 is for answer completeness, ASQA (Stelmakh et al.,

2022), and ELI5 (Fan et al., 2019). The ASQA
𝑚

1 ∑︁𝑖 ∑︁𝑛
S dataset consists of 6K ambiguous factoid questions
RC = 1

𝑚 𝑤𝑘
𝑖 𝑖 ∈ 𝑗𝑠
𝑘=1 𝑠= with long-form answers synthesized from multiple

1
sources to resolve the ambiguities. ELI5 consists

where 1𝑤𝑘
𝑖 ∈ 𝑗 is 1 if token 𝑤𝑘 is in the j stificat

𝑠 𝑖 u ion of 270K long-form answers covering general topics

20442



Consistency
Approach Model Accuracy (%) Weighted

Exact (↑) Adjacent (↓) Different (↓) Accuracy (%) (↑) Score (𝑆𝑅𝐶 ) (↑)

Zero-shot LLaMA2-13B 23.53 ± 1.60 7.84 ± 0.00 68.63 ± 1.60 34.31 ± 1.44 0.52 ± 0.02
Zero-shot GPT-3.5-Turbo 25.49 11.76 62.75 37.65 0.99
Fine-tuning w/ HQ2A LLaMA2-13B 37.25 ± 0.00 24.18 ± 0.92 38.56 ± 0.93 53.20 ± 0.37 0.80 ± 0.01

Table 3: Accuracy and Consistency Score (𝑆𝑅𝐶) of zero-shot and fine-tuned models in detecting sentence-level
errors on HQ2A, averaged over three runs with standard deviations (except for GPT-3.5). Best scores are in bold.

from the Reddit forum "Explain Like I’m Five". match, precede or follow human-annotated error
We evaluate the refined answers using TIGER- sentences, capturing instances where the model

Score, a trained reference-free metric that identifies detects completely unrelated error spans.
errors in LLM-generated text and assigns an error To capture the overall error detection perfor-
score based on error severity. Specifically, we use mance across the defined evaluation categories, we
the LLaMA-7B trained version of TIGERScore, introduce a weighted accuracy metric:
which highly correlates with humans for error de-
tection in LFQA tasks (Jiang et al., 2023b) while

Exact matches s
being cost-effective. We also measure how well our 𝑤Exact · # + 𝑤 · # Adjacent matche

Total errors Adj Total errors
Accuracy

refinement approach corrects errors identified by wt =
+ Different matches
𝑤Diff · #

.
Total errors

TIGERScore using precision, recall, and F1 score
metrics. Finally, we conduct a human evaluation where 𝑤Exact, 𝑤Adj, and 𝑤Diff represent the weights
to assess the comprehensiveness and preference of assigned to each category according to its rela-
refined answers compared to gold answers. tive importance. We assign 𝑤Exact = 1.0 to reward

the model’s capability of correctly detecting errors
5 Results and 𝑤Adj = 0.5 to quantify the importance of near-

misses which may still provide insight on the actual
We explore several research questions: (1) Can our errors. Consequently, 𝑤Diff = 0.1 to penalize the
learned feedback model detect errors in LFQA sys- model for its incorrect error detection.
tems and help in downstream answer refinement In Table 3, we show the sentence-level error de-
task? (2) Does fine-grained feedback produce bet- tection accuracy of the zero-shot LLaMA2-13B
ter quality LFQA answers than coarse-grained feed- and GPT-3.5-Turbo and our fine-tuned feedback
back? (3) Does fine-grained feedback help miti- models compared to the strong human baseline.
gate errors and improve the comprehensiveness of Our fine-tuned feedback model improves the de-
LFQA answers? (4) Are comprehensive answers tection of correct error spans (exact) by ~14% and
from our approach preferred by humans? ~12% and reduces the detection of incorrect error

spans (different) by ~30% and ~24% compared to
5.1 Detecting Errors via Feedback Model the zero-shot feedback models LLaMA2-13B and
To measure the error detection accuracy of our feed- GPT-3.5-Turbo, respectively. Specifically, our feed-
back model, we propose an evaluation across three back model outperforms GPT-3.5-Turbo by ~16%
fine-grained categories: (1) EXACT: Erroneous on our weighted accuracy metric while maintaining
sentences identified by the model exactly match a high consistency score of 0.80. This shows that
the human-annotated erroneous sentences. This the model effectively learns to identify complete-
category represents the most stringent evaluation ness errors, even when fine-tuned on limited but
of model performance. (2) ADJACENT: Erroneous high-quality HQ2A samples, aligning with recent
sentences identified by the model are adjacent to, findings (Zhou et al., 2023; Xia et al., 2024) on fine-
or closely related to, human-annotated erroneous tuning with small but carefully curated datasets. In
sentences. Here, "adjacent" refers to a sentence Appendix B.2, we discuss systematic patterns of
preceding or following the human-annotated error errors learned by the feedback model.
sentence. These near-misses may still aid in under- We further evaluate our error feedback model by
standing or resolving the error due to the contextual comparing the gap in the downstream LFQA re-
relation between the preceding/following sentence finement task when we use human-annotated error
and the actual error sentence. (3) DIFFERENT: Er- feedback. This evaluation measures the effective-
roneous sentences identified by the model do not ness of our feedback model in guiding the refine-

20443



TIGERScore Error Correction
Dataset Approach

% Error samples (↓) Error score (↓) Precision (↑) Recall (↑) F1 (↑)

Human feedback 2.61 ± 0.92 0.09 ± 0.01 0.86 ± 0.04 1.00 ± 0.00 0.94 ± 0.02
HQ2A

Baseline 19.61 0.63 - - -
Zero-shot 15.69 ± 0.00 0.34 ± 0.00 0.56 ± 0.00 0.90 ± 0.00 0.69 ± 0.00

Improve 1.31 ± 0.92 0.05 ± 0.04 1.00 ± 0.00 0.93 ± 0.05 0.97 ± 0.02

Generic 1.31 ± 0.92 0.05 ± 0.03 0.97 ± 0.04 0.97 ± 0.05 0.97 ± 0.02

EIR (Ours) 0.65 ± 0.92 0.03 ± 0.04 0.97 ± 0.04 1.00 ± 0.00 0.98 ± 0.02

Baseline 34.81 1.20 - - -
ASQA

Zero-shot 35.02 ± 0.00 1.08 ± 0.00 0.50 ± 0.00 0.62 ± 0.00 0.55 ± 0.00
Improve 20.85 ± 1.00 0.68 ± 0.03 0.70 ± 0.02 0.71 ± 0.01 0.70 ± 0.01

Generic 18.67 ± 0.52 0.61 ± 0.01 0.72 ± 0.01 0.75 ± 0.01 0.74 ± 0.00

EIR (Ours) 16.63 ± 0.41 0.51 ± 0.02 0.73 ± 0.00 0.82 ± 0.02 0.77 ± 0.01

Baseline 22.93 0.82 - - -
ELI5

Zero-shot 9.61 ± 0.00 0.27 ± 0.00 0.74 ± 0.00 0.89 ± 0.00 0.81 ± 0.00
Improve 10.05 ± 0.18 0.36 ± 0.02 0.75 ± 0.00 0.86 ± 0.00 0.80 ± 0.00

Generic 6.06 ± 0.23 0.22 ± 0.01 0.84 ± 0.01 0.91 ± 0.00 0.87 ± 0.00

EIR (Ours) 3.81 ± 0.30 0.13 ± 0.01 0.88 ± 0.01 0.96 ± 0.01 0.92 ± 0.01

Table 4: Results on the quality of original answers from the datasets (BASELINE); answers from zero-shot prompting
LLaMA2-13B-chat (ZERO-SHOT); answers refined with coarse-grained feedback (IMPROVE and GENERIC), fine-
grained feedback (EIR) and human feedback on HQ2A. Reported results are averages over three iterations with
standard deviations. Best results are in bold green, and the second-best results are in orange. We report results with
LLaMA3-8B-Instruct (Dubey et al., 2024) and Mistral-7B-Instruct-v0.3 (Jiang et al., 2023a) models in Appendix E.3.

ment of long-form answers and reducing errors. In improving F1 scores by ~5%, on average.
Table 4, we present the refinement performance We also investigated the impact of aligning the
with our feedback model compared to the expert refinement model with human preferences from
human feedback on HQ2A. Our feedback model HQ2A with DPO. Despite promising initial results
reduces error samples by 2% and improves the F1 in reducing LFQA errors (Appendix E.1), the re-
score by 4% over expert human feedback, validat- sulting refinement model ultimately did not outper-
ing its effectiveness in refining LFQA answers. form the vanilla refinement model (Appendix E.2).

5.2 Fine- vs. Coarse-Grained Feedback 5.3 Human Evaluation
Table 4 presents the quality of BASELINE an- We conduct a human evaluation with three anno-
swers (original dataset instances) refined using tators to test the completeness and overall quality
coarse- and fine-grained feedback. We also evalu- of the answers generated using our refinement ap-
ate answers generated through zero-shot prompting proach. For 50 questions each from the HQ2A,
LLaMA2-13B-chat for comparison. ASQA, and ELI5 datasets, we present annotators

Our results show that inadequate feedback can with a pair of answers—one from the dataset (base-
deteriorate generation quality. While directly line) and one refined by our method.
prompting the refinement model to generate an- To evaluate completeness, we adopt a compara-
swers (ZERO-SHOT) or improve answers with- tive comprehensiveness metric: annotators judge
out detailed feedback (IMPROVE) performs better which answer more fully addresses all parts of the
than the baseline, using more targeted feedback, question, based on our defined criteria for identi-
such as asking the model to complete the answer fying completeness errors (see Appendix F.2). To
(GENERIC), consistently leads to higher-quality assess the overall answer quality, annotators con-
LFQA answers. In contrast, fine-grained feedback sider broader factors, such as the factual precision
from our error detection model (EIR) outperforms and relevance (Appendix F.2), when selecting their
coarse-grained feedback and fine-grained human preferred answer.
feedback (on HQ2A), reducing error samples and Table 5 shows the results of our human eval-
error scores by ~3% and ~Δ38%, respectively, and uation of the BASELINE and REFINED answers.

20444



Dataset Pref. Comprehensiveness(↑) Overall(↑) hallucinate if the consistency score is low (< 0.80).
Training larger models with more high quality data

HQ2A Baseline 0.00% 7.84%
Refined 100% 92.16% might be an interesting future work to get better re-
Tie 0.00% -

sults. Lastly, in our refinement approach, we have
ASQA Baseline 0.00% 40.00%

Refined 18.00% 60.00% experimented with the instruction-tuned variants
Tie 82.00% - of the LLaMA2, LLaMA3, and Mistral models.

ELI5 Baseline 0.00% 0.00% Models with better or worse instruction following
Refined 62.00% 100%
Tie 38.00% - capabilities may give different results, and improv-

ing the refinement process can be a great future
Table 5: Human evaluation results on the comprehen- direction to mitigate errors.
siveness and preference of answers refined with EIR
over the original answers from the datasets (BASELINE). Ethics and Broader Impact Statement
Details on the human agreement are in Appendix E.4.

The expert annotation data collection protocol has
We observe that refined answers are considered been determined to be exempt from review by an
more comprehensive in ~60% of cases and pre- IRB board. All the collected data will be publicly
ferred overall in ~84% of comparisons on average available under the CC BY-SA 4.0 license. We hire
across all evaluated datasets, demonstrating im- annotators on the academic annotation platform
proved completeness and quality over the baseline Prolific and gather no sensitive user information ex-
answers. cept demographics and annotator performance data.

6 Conclusion We examined the collected data and ascertained
that it contains no toxic or harmful content.

We introduce HALUQUESTQA, a dataset of expert
judgments on fine-grained errors in LFQA. Using Acknowledgements
our dataset, we analyze the pitfalls of human and

This research work is funded by the German Re-
model long-form answers, identifying issues with

search Foundation (DFG) as part of the UKP-
comprehensiveness and unhelpful references. To

SQuARE project (grant GU 798/29-1) and by the
address these, we propose ERROR-INFORMED RE-

German Federal Ministry of Education and Re-
FINEMENT, an approach that uses signals from our

search and the Hessian Ministry of Higher Ed-
learned feedback model to refine LLM responses.

ucation, Research, Science and the Arts within
Our feedback model outperforms baseline feedback

their joint support of the National Research Cen-
models and expert human feedback in guiding an-

ter for Applied Cybersecurity ATHENE. Yixiao
swer refinement and reducing errors. A human eval-

Song and Mohit Iyyer are supported by the award
uation confirms the effectiveness of our approach,

IIS-2312949 from the National Science Foundation
with participants finding our refined answers more

(NSF).
comprehensive and preferable to baseline outputs.

We thank Sukannya Purkayastha and Haritz
Limitations Puerto for their insightful feedback on the paper

and Manika Arvind Arora for the valuable feedback
Despite providing an in-depth analysis on errors in on the annotation setup. Lastly, we are grateful to
human and model generated responses, our work our dedicated annotators who helped create the
only focusses on the LFQA task. Thus, we encour- HaluQuestQA dataset.
age future work to apply our findings to different
tasks such as summarization, translation, etc. We
study a diverse but limited scope of long-form an- References
swers drawn from online community platforms.
More diverse questions from different domains Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda

Askell, Anna Chen, Nova DasSarma, Dawn Drain,
such as education or commercial may have dif- Stanislav Fort, Deep Ganguli, Tom Henighan,
ferent issues and might be to be evaluated in a Nicholas Joseph, Saurav Kadavath, Jackson Kernion,
different way. Tom Conerly, Sheer El Showk, Nelson Elhage, Zac

Our trained error detection model shows high Hatfield-Dodds, Danny Hernandez, Tristan Hume,
Scott Johnston, Shauna Kravec, Liane Lovitt, Neel

correlation with human annotations but relies on a Nanda, Catherine Olsson, Dario Amodei, Tom B.
high consistency of model outputs. The model may Brown, Jack Clark, Sam McCandlish, Chris Olah,

20445



Benjamin Mann, and Jared Kaplan. 2022a. Train- Geffert, Jana Vranes, Jason Park, Jay Mahadeokar,
ing a helpful and harmless assistant with rein- Jeet Shah, Jelmer van der Linde, Jennifer Billock,
forcement learning from human feedback. CoRR, Jenny Hong, Jenya Lee, Jeremy Fu, Jianfeng Chi,
abs/2204.05862. Jianyu Huang, Jiawen Liu, Jie Wang, Jiecao Yu,

Joanna Bitton, Joe Spisak, Jongsoo Park, Joseph
Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Rocca, Joshua Johnstun, Joshua Saxe, Junteng Jia,

Amanda Askell, Jackson Kernion, Andy Jones, Anna Kalyan Vasuden Alwala, Kartikeya Upasani, Kate
Chen, Anna Goldie, Azalia Mirhoseini, Cameron Plawiak, Ke Li, Kenneth Heafield, Kevin Stone, and
McKinnon, Carol Chen, Catherine Olsson, Christo- et al. 2024. The llama 3 herd of models. CoRR,
pher Olah, Danny Hernandez, Dawn Drain, Deep abs/2407.21783.
Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez,
Jamie Kerr, Jared Mueller, Jeffrey Ladish, Joshua Angela Fan, Yacine Jernite, Ethan Perez, David Grang-
Landau, Kamal Ndousse, Kamile Lukosiute, Liane ier, Jason Weston, and Michael Auli. 2019. ELI5:
Lovitt, Michael Sellitto, Nelson Elhage, Nicholas Long form question answering. In Proceedings of
Schiefer, Noemí Mercado, Nova DasSarma, Robert the 57th Annual Meeting of the Association for Com-
Lasenby, Robin Larson, Sam Ringer, Scott John- putational Linguistics, pages 3558–3567, Florence,
ston, Shauna Kravec, Sheer El Showk, Stanislav Fort, Italy. Association for Computational Linguistics.
Tamera Lanham, Timothy Telleen-Lawton, Tom Con-
erly, Tom Henighan, Tristan Hume, Samuel R. Bow- Markus Freitag, George F. Foster, David Grangier,
man, Zac Hatfield-Dodds, Ben Mann, Dario Amodei, Viresh Ratnakar, Qijun Tan, and Wolfgang Macherey.
Nicholas Joseph, Sam McCandlish, Tom Brown, and 2021. Experts, errors, and context: A large-scale
Jared Kaplan. 2022b. Constitutional AI: harmless- study of human evaluation for machine translation.
ness from AI feedback. CoRR, abs/2212.08073. CoRR, abs/2104.14478.

Meghana Moorthy Bhat, Rui Meng, Ye Liu, Yingbo Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei
Zhou, and Semih Yavuz. 2023. Investigating an- Liu. 2023. Gptscore: Evaluate as you desire. CoRR,
swerability of llms for long-form question answering. abs/2302.04166.
CoRR, abs/2309.08210.

Tanya Goyal and Greg Durrett. 2020. Evaluating factu-
Jeremy R. Cole, Michael J. Q. Zhang, Daniel Gillick, Ju- ality in generation with dependency-level entailment.

lian Eisenschlos, Bhuwan Dhingra, and Jacob Eisen- CoRR, abs/2010.05478.
stein. 2023. Selectively answering ambiguous ques-
tions. In Proceedings of the 2023 Conference on Tanya Goyal, Junyi Jessy Li, and Greg Durrett. 2022.
Empirical Methods in Natural Language Process- SNaC: Coherence error detection for narrative sum-
ing, EMNLP 2023, Singapore, December 6-10, 2023, marization. In Proceedings of the 2022 Conference
pages 530–543. Association for Computational Lin- on Empirical Methods in Natural Language Process-
guistics. ing, pages 444–463, Abu Dhabi, United Arab Emi-

rates. Association for Computational Linguistics.
Steven Coyne and Keisuke Sakaguchi. 2023. An analy-

sis of gpt-3’s performance in grammatical error cor- Andrew F. Hayes and Klaus Krippendorff. 2007. An-
rection. CoRR, abs/2303.14342. swering the call for a standard reliability measure for

coding data. Communication Methods and Measures,
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, 1(1):77–89.

Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman,
Akhil Mathur, Alan Schelten, Amy Yang, Angela Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan
Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and
Archi Mitra, Archie Sravankumar, Artem Korenev, Weizhu Chen. 2022. Lora: Low-rank adaptation of
Arthur Hinsvark, Arun Rao, Aston Zhang, Aurélien large language models. In The Tenth International
Rodriguez, Austen Gregerson, Ava Spataru, Bap- Conference on Learning Representations, ICLR 2022,
tiste Rozière, Bethany Biron, Binh Tang, Bobbie Virtual Event, April 25-29, 2022. OpenReview.net.
Chern, Charlotte Caucheteux, Chaya Nayak, Chloe
Bi, Chris Marra, Chris McConnell, Christian Keller, Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu,
Christophe Touret, Chunyang Wu, Corinne Wong, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Andrea
Cristian Canton Ferrer, Cyrus Nikolaidis, Damien Al- Madotto, and Pascale Fung. 2022. Survey of hal-
lonsius, Daniel Song, Danielle Pintz, Danny Livshits, lucination in natural language generation. CoRR,
David Esiobu, Dhruv Choudhary, Dhruv Mahajan, abs/2202.03629.
Diego Garcia-Olano, Diego Perino, Dieuwke Hupkes,
Egor Lakomkin, Ehab AlBadawy, Elina Lobanova, Ziwei Ji, Tiezheng Yu, Yan Xu, Nayeon Lee, Etsuko
Emily Dinan, Eric Michael Smith, Filip Radenovic, Ishii, and Pascale Fung. 2023. Towards mitigat-
Frank Zhang, Gabriel Synnaeve, Gabrielle Lee, Geor- ing hallucination in large language models via self-
gia Lewis Anderson, Graeme Nail, Grégoire Mialon, reflection. CoRR, abs/2310.06271.
Guan Pang, Guillem Cucurell, Hailey Nguyen, Han-
nah Korevaar, Hu Xu, Hugo Touvron, Iliyan Zarov, Albert Q. Jiang, Alexandre Sablayrolles, Arthur Men-
Imanol Arrieta Ibarra, Isabel M. Kloumann, Ishan sch, Chris Bamford, Devendra Singh Chaplot, Diego
Misra, Ivan Evtimov, Jade Copet, Jaewon Lee, Jan de Las Casas, Florian Bressand, Gianna Lengyel,

20446



Guillaume Lample, Lucile Saulnier, Lélio Re- Junyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun
nard Lavaud, Marie-Anne Lachaux, Pierre Stock, Nie, and Ji-Rong Wen. 2023. Halueval: A large-
Teven Le Scao, Thibaut Lavril, Thomas Wang, Timo- scale hallucination evaluation benchmark for large
thée Lacroix, and William El Sayed. 2023a. Mistral language models. CoRR, abs/2305.11747.
7b. CoRR, abs/2310.06825.

Chin-Yew Lin. 2004. ROUGE: A package for auto-
Dongfu Jiang, Yishan Li, Ge Zhang, Wenhao Huang, matic evaluation of summaries. In Text Summariza-

Bill Yuchen Lin, and Wenhu Chen. 2023b. Tiger- tion Branches Out, pages 74–81, Barcelona, Spain.
score: Towards building explainable metric for all Association for Computational Linguistics.
text generation tasks. Nelson F. Liu, Tianyi Zhang, and Percy Liang. 2023a.

Evaluating verifiability in generative search engines.
Gangwoo Kim, Sungdong Kim, Byeongguk Jeon, Joon- In Findings of the Association for Computational Lin-

suk Park, and Jaewoo Kang. 2023. Tree of clarifica- guistics: EMNLP 2023, Singapore, December 6-10,
tions: Answering ambiguous questions with retrieval- 2023, pages 7001–7025. Association for Computa-
augmented large language models. In Proceedings of tional Linguistics.
the 2023 Conference on Empirical Methods in Natu-
ral Language Processing, EMNLP 2023, Singapore, Yixin Liu, Alexander R. Fabbri, Pengfei Liu, Yilun
December 6-10, 2023, pages 996–1009. Association Zhao, Linyong Nan, Ruilin Han, Simeng Han,
for Computational Linguistics. Shafiq Joty, Chien-Sheng Wu, Caiming Xiong, and

Dragomir Radev. 2023b. Revisiting the gold stan-
Jan-Christoph Klie, Michael Bugert, Beto Boullosa, dard: Grounding summarization evaluation with ro-

Richard Eckart de Castilho, and Iryna Gurevych. bust human evaluation. In Proceedings of the 61st
2018. The INCEpTION platform: Machine-assisted Annual Meeting of the Association for Computational
and knowledge-oriented interactive annotation. In Linguistics (Volume 1: Long Papers), ACL 2023,
Proceedings of the 27th International Conference on Toronto, Canada, July 9-14, 2023, pages 4140–4170.
Computational Linguistics: System Demonstrations, Association for Computational Linguistics.
pages 5–9, Santa Fe, New Mexico. Association for
Computational Linguistics. Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler

Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon,
Tom Kocmi, Vilém Zouhar, Eleftherios Avramidis, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,

Roman Grundkiewicz, Marzena Karpinska, Maja Shashank Gupta, Bodhisattwa Prasad Majumder,
Popovic, Mrinmaya Sachan, and Mariya Shmatova. Katherine Hermann, Sean Welleck, Amir Yazdan-
2024. Error span annotation: A balanced approach bakhsh, and Peter Clark. 2023. Self-refine: Itera-
for human evaluation of machine translation. CoRR, tive refinement with self-feedback. In Advances in
abs/2406.11580. Neural Information Processing Systems 36: Annual

Conference on Neural Information Processing Sys-
tems 2023, NeurIPS 2023, New Orleans, LA, USA,

Kalpesh Krishna, Aurko Roy, and Mohit Iyyer. 2021. December 10 - 16, 2023.
Hurdles to progress in long-form question answering.
In Proceedings of the 2021 Conference of the North Christopher Malon and Xiaodan Zhu. 2024. Self-
American Chapter of the Association for Computa- consistent decoding for more factual open responses.
tional Linguistics: Human Language Technologies, CoRR, abs/2403.00696.
pages 4940–4957, Online. Association for Computa-
tional Linguistics. Potsawee Manakul, Adian Liusie, and Mark J. F. Gales.

2023. Selfcheckgpt: Zero-resource black-box hal-
Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying lucination detection for generative large language

Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. models. In Proceedings of the 2023 Conference on
Gonzalez, Hao Zhang, and Ion Stoica. 2023. Effi- Empirical Methods in Natural Language Process-
cient memory management for large language model ing, EMNLP 2023, Singapore, December 6-10, 2023,
serving with pagedattention. In Proceedings of the pages 9004–9017. Association for Computational
ACM SIGOPS 29th Symposium on Operating Systems Linguistics.
Principles. Jacob Menick, Maja Trebacz, Vladimir Mikulik, John

Aslanides, H. Francis Song, Martin J. Chadwick,
Philippe Laban, Tobias Schnabel, Paul N. Bennett, and Mia Glaese, Susannah Young, Lucy Campbell-

Marti A. Hearst. 2022. SummaC: Re-visiting NLI- Gillingham, Geoffrey Irving, and Nat McAleese.
based models for inconsistency detection in summa- 2022. Teaching language models to support answers
rization. Transactions of the Association for Compu- with verified quotes. CoRR, abs/2203.11147.
tational Linguistics, 10:163–177.

Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike
Nayeon Lee, Wei Ping, Peng Xu, Mostofa Patwary, Pas- Lewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer,

cale Fung, Mohammad Shoeybi, and Bryan Catan- Luke Zettlemoyer, and Hannaneh Hajishirzi. 2023.
zaro. 2022. Factuality enhanced language models for Factscore: Fine-grained atomic evaluation of fac-
open-ended text generation. In Advances in Neural tual precision in long form text generation. CoRR,
Information Processing Systems. abs/2305.14251.

20447



Dor Muhlgay, Ori Ram, Inbal Magar, Yoav Levine, Processing, pages 8273–8288, Abu Dhabi, United
Nir Ratner, Yonatan Belinkov, Omri Abend, Kevin Arab Emirates. Association for Computational Lin-
Leyton-Brown, Amnon Shashua, and Yoav Shoham. guistics.
2023. Generating benchmarks for factuality evalua-
tion of language models. CoRR, abs/2307.06908. Dan Su, Xiaoguang Li, Jindi Zhang, Lifeng Shang, Xin

Jiang, Qun Liu, and Pascale Fung. 2022. Read before
Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, generate! faithful long form question answering with

Long Ouyang, Christina Kim, Christopher Hesse, machine reading. In Findings of the Association for
Shantanu Jain, Vineet Kosaraju, William Saunders, Computational Linguistics: ACL 2022, pages 744–
Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen 756, Dublin, Ireland. Association for Computational
Krueger, Kevin Button, Matthew Knight, Benjamin Linguistics.
Chess, and John Schulman. 2021. Webgpt: Browser-
assisted question-answering with human feedback. Liangtai Sun, Yang Han, Zihan Zhao, Da Ma, Zhennan
CoRR, abs/2112.09332. Shen, Baocai Chen, Lu Chen, and Kai Yu. 2024. Sci-

eval: A multi-level large language model evaluation
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, benchmark for scientific research. In Thirty-Eighth

Carroll L. Wainwright, Pamela Mishkin, Chong AAAI Conference on Artificial Intelligence, AAAI
Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, 2024, Thirty-Sixth Conference on Innovative Applica-
John Schulman, Jacob Hilton, Fraser Kelton, Luke tions of Artificial Intelligence, IAAI 2024, Fourteenth
Miller, Maddie Simens, Amanda Askell, Peter Welin- Symposium on Educational Advances in Artificial
der, Paul F. Christiano, Jan Leike, and Ryan Lowe. Intelligence, EAAI 2014, February 20-27, 2024, Van-
2022. Training language models to follow instruc- couver, Canada, pages 19053–19061. AAAI Press.
tions with human feedback. In Advances in Neural
Information Processing Systems 35: Annual Confer- Liyan Tang, Igor Shalyminov, Amy Wing mei Wong,
ence on Neural Information Processing Systems 2022, Jon Burnsky, Jake W. Vincent, Yu’an Yang, Siffi
NeurIPS 2022, New Orleans, LA, USA, November 28 Singh, Song Feng, Hwanjun Song, Hang Su, Lijia
- December 9, 2022. Sun, Yi Zhang, Saab Mansour, and Kathleen McK-

eown. 2024. Tofueval: Evaluating hallucinations of
Kishore Papineni, Salim Roukos, Todd Ward, and Wei- llms on topic-focused dialogue summarization.

Jing Zhu. 2002. Bleu: a method for automatic evalu-
ation of machine translation. In Proceedings of the Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann
40th Annual Meeting of the Association for Compu- Dubois, Xuechen Li, Carlos Guestrin, Percy
tational Linguistics, pages 311–318, Philadelphia, Liang, and Tatsunori B. Hashimoto. 2023. Stan-
Pennsylvania, USA. Association for Computational ford alpaca: An instruction-following llama
Linguistics. model. https://github.com/tatsu-lab/

stanford_alpaca.
Rafael Rafailov, Archit Sharma, Eric Mitchell, Christo-

pher D. Manning, Stefano Ermon, and Chelsea Finn. Katherine Tian, Eric Mitchell, Huaxiu Yao, Christo-
2023. Direct preference optimization: Your language pher D. Manning, and Chelsea Finn. 2023. Fine-
model is secretly a reward model. In Advances in tuning language models for factuality. CoRR,
Neural Information Processing Systems 36: Annual abs/2311.08401.
Conference on Neural Information Processing Sys-
tems 2023, NeurIPS 2023, New Orleans, LA, USA, Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
December 10 - 16, 2023. Martinet, Marie-Anne Lachaux, Timothée Lacroix,

Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal
Francesco Salvi, Manoel Horta Ribeiro, Riccardo Gal- Azhar, Aurélien Rodriguez, Armand Joulin, Edouard

lotti, and Robert West. 2024. On the conversational Grave, and Guillaume Lample. 2023a. Llama: Open
persuasiveness of large language models: A random- and efficient foundation language models. CoRR,
ized controlled trial. CoRR, abs/2403.14380. abs/2302.13971.

Chris Samarinas, Alexander Krubner, Alireza Salemi, Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
Youngwoo Kim, and Hamed Zamani. 2025. Beyond bert, Amjad Almahairi, Yasmine Babaei, Nikolay
factual accuracy: Evaluating coverage of diverse fac- Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti
tual information in long-form text generation. CoRR, Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-
abs/2501.03545. Ferrer, Moya Chen, Guillem Cucurull, David Esiobu,

Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,
Shokri Z. Selim and M. A. Ismail. 1984. K-means- Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-

type algorithms: A generalized convergence theorem thony Hartshorn, Saghar Hosseini, Rui Hou, Hakan
and characterization of local optimality. IEEE Trans. Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,
Pattern Anal. Mach. Intell., 6(1):81–87. Isabel Kloumann, Artem Korenev, Punit Singh Koura,

Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-
Ivan Stelmakh, Yi Luan, Bhuwan Dhingra, and Ming- ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-

Wei Chang. 2022. ASQA: Factoid questions meet tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-
long-form answers. In Proceedings of the 2022 Con- bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
ference on Empirical Methods in Natural Language stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,

20448



Ruan Silva, Eric Michael Smith, Ranjan Subrama- Mengzhou Xia, Sadhika Malladi, Suchin Gururangan,
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay- Sanjeev Arora, and Danqi Chen. 2024. LESS: se-
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu, lecting influential data for targeted instruction tuning.
Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, In Forty-first International Conference on Machine
Melanie Kambadur, Sharan Narang, Aurélien Ro- Learning, ICML 2024, Vienna, Austria, July 21-27,
driguez, Robert Stojnic, Sergey Edunov, and Thomas 2024. OpenReview.net.
Scialom. 2023b. Llama 2: Open foundation and
fine-tuned chat models. CoRR, abs/2307.09288. Fangyuan Xu, Yixiao Song, Mohit Iyyer, and Eunsol

Choi. 2023a. A critical evaluation of evaluations
Tianlu Wang, Ping Yu, Xiaoqing Ellen Tan, Sean for long-form question answering. In Proceedings

O’Brien, Ramakanth Pasunuru, Jane Dwivedi-Yu, of the 61st Annual Meeting of the Association for
Olga Golovneva, Luke Zettlemoyer, Maryam Fazel- Computational Linguistics (Volume 1: Long Papers),
Zarandi, and Asli Celikyilmaz. 2023. Shepherd: pages 3225–3245, Toronto, Canada. Association for
A critic for language model generation. CoRR, Computational Linguistics.
abs/2308.04592.

Wenda Xu, Daniel Deutsch, Mara Finkelstein, Juraj
Xiaoxuan Wang, Ziniu Hu, Pan Lu, Yanqiao Zhu, Jieyu Juraska, Biao Zhang, Zhongtao Liu, William Yang

Zhang, Satyen Subramaniam, Arjun R. Loomba, Wang, Lei Li, and Markus Freitag. 2024. Llmrefine:
Shichang Zhang, Yizhou Sun, and Wei Wang. Pinpointing and refining large language models via
2024a. Scibench: Evaluating college-level scientific fine-grained actionable feedback.
problem-solving abilities of large language models.
In Forty-first International Conference on Machine Wenda Xu, Danqing Wang, Liangming Pan, Zhenqiao
Learning, ICML 2024, Vienna, Austria, July 21-27, Song, Markus Freitag, William Wang, and Lei Li.
2024. OpenReview.net. 2023b. INSTRUCTSCORE: towards explainable

text generation evaluation with automatic feedback.
Yuqi Wang, Lyuhao Chen, Songcheng Cai, Zhijian Xu, In Proceedings of the 2023 Conference on Empirical

and Yilun Zhao. 2024b. Revisiting automated evalu- Methods in Natural Language Processing, EMNLP
ation for long-form table question answering. In Pro- 2023, Singapore, December 6-10, 2023, pages 5967–
ceedings of the 2024 Conference on Empirical Meth- 5994. Association for Computational Linguistics.
ods in Natural Language Processing, pages 14696– Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.
14706, Miami, Florida, USA. Association for Com- Weinberger, and Yoav Artzi. 2020. Bertscore: Evalu-
putational Linguistics. ating text generation with BERT. In 8th International

Conference on Learning Representations, ICLR 2020,
Sean Welleck, Ximing Lu, Peter West, Faeze Brah- Addis Ababa, Ethiopia, April 26-30, 2020. OpenRe-

man, Tianxiao Shen, Daniel Khashabi, and Yejin view.net.
Choi. 2023. Generating sequences by learning to
self-correct. In The Eleventh International Confer- Ming Zhong, Yang Liu, Da Yin, Yuning Mao, Yizhu
ence on Learning Representations, ICLR 2023, Ki- Jiao, Pengfei Liu, Chenguang Zhu, Heng Ji, and
gali, Rwanda, May 1-5, 2023. OpenReview.net. Jiawei Han. 2022. Towards a unified multi-

dimensional evaluator for text generation. In Pro-
Ka Wong, Praveen K. Paritosh, and Lora Aroyo. 2021. ceedings of the 2022 Conference on Empirical Meth-

Cross-replication reliability - an empirical approach ods in Natural Language Processing, EMNLP 2022,
to interpreting inter-rater reliability. In Proceedings Abu Dhabi, United Arab Emirates, December 7-11,
of the 59th Annual Meeting of the Association for 2022, pages 2023–2038. Association for Computa-
Computational Linguistics and the 11th International tional Linguistics.
Joint Conference on Natural Language Processing,
ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer,
Event, August 1-6, 2021, pages 7053–7065. Associa- Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping
tion for Computational Linguistics. Yu, Lili Yu, Susan Zhang, Gargi Ghosh, Mike Lewis,

Luke Zettlemoyer, and Omer Levy. 2023. LIMA:
Haoran Wu, Wenxuan Wang, Yuxuan Wan, Wenxiang less is more for alignment. In Advances in Neural

Jiao, and Michael R. Lyu. 2023a. Chatgpt or gram- Information Processing Systems 36: Annual Confer-
marly? evaluating chatgpt on grammatical error cor- ence on Neural Information Processing Systems 2023,
rection benchmark. CoRR, abs/2303.13648. NeurIPS 2023, New Orleans, LA, USA, December 10

- 16, 2023.
Zeqiu Wu, Yushi Hu, Weijia Shi, Nouha Dziri, Alane

Suhr, Prithviraj Ammanabrolu, Noah A. Smith, Mari Daniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B.
Ostendorf, and Hannaneh Hajishirzi. 2023b. Fine- Brown, Alec Radford, Dario Amodei, Paul F. Chris-
grained human feedback gives better rewards for tiano, and Geoffrey Irving. 2019. Fine-tuning lan-
language model training. In Advances in Neural guage models from human preferences. CoRR,
Information Processing Systems 36: Annual Confer- abs/1909.08593.
ence on Neural Information Processing Systems 2023,
NeurIPS 2023, New Orleans, LA, USA, December 10
- 16, 2023.

20449



A Data Collection and Analysis Error Type Annotated Spans

This section presents additional insights on our Phrase- Sentence- Multi-sentence-
level level level

HaluQuestQA (HQ2A) dataset.
Question Mis- 38.89% 52.47% 8.64%

A.1 Domain Classification conception
Factuality 42.40% 44.88% 12.72%

The questions on the ELI5 are classified into do- Relevance 25.00% 39.13% 35.87%
mains via the FLAIR label (tag containing post in- Completeness 35.81% 34.63% 29.56%
formation), which lets us perform domain-specific References 31.24% 30.77% 38.00%
analysis. For unclassified categories (like History Average 34.67% 40.38% 24.96%
and Law), we cluster the OTHER category ques-
tions (not in pre-defined ELI5 domains), using Table 6: Overview of error types and the corresponding
K-means clustering (Selim and Ismail, 1984) and annotation distribution across phrase-level, sentence-
identify the domain-specific questions. For each level, and multi-sentence-level errors.
domain, we sample between 100-200 questions
with their highest-voted answers.

and multi-sentence). Our findings show that ex-
A.2 Answer Length Distribution perts identify phrase-level errors in approximately
Figure 4 compares the length distribution of human- 35% of the cases, indicating that a substantial por-
written and model-generated answers. We observe tion of errors are nuanced and cannot be effectively
that the length of human and model answers is captured at the sentence level. This highlights the
comparable, resulting in a fair evaluation. Across need to employ fine-grained span-level annotations
all domains, the length of collected answers ranges to enhance the evaluation process, as they provide
between 50-500 words with an average length of deeper insight into the nature and exact location
100 words. of errors, ultimately leading to improved answer

quality by targeting specific errors.
Human Model

600 A.5 Expert (dis)agreement.
500 In Table 1, we report Krippendorf’s alpha (Hayes
400 and Krippendorff, 2007) as a measure of agreement
300 for experts’ overall answer preference. Our expert
200 annotators achieve moderate agreement in technol-
100

ogy, history, and law, fair agreement in biology and
0

Physics Chemistry Biology Technology Economics History Law economics, and slight agreement in physics and
Category chemistry.5 We emphasize that the disagreement

Figure 4: Answer length distribution of human-written between experts is not a failure of our evaluation.
and model-generated answers (H/M) in our expert- Instead, it highlights the challenges of identify-
annotated dataset. ing fine-grained errors in answers, affecting over-

all preference. Moreover, prior work has similar
findings for human disagreement in LFQA evalua-

A.3 Overall Answer Preference tion (Xu et al., 2023a).
In Figure 5, we plot the word frequency distribution
of the free-form answer justifications provided by B Prompts
our expert annotators. Apart from our considered This section lists the prompts for data collection,
evaluation aspects, we observe that the annotators training the error detection model, and refining
also find answers clarity, conciseness, and ease of answers using our Error-informed approach.
understanding helpful in deciding the overall best
answer. We encourage future LFQA research to B.1 Data Collection
consider these aspects in their evaluation. We prompt GPT-4 in a zero-shot manner to
A.4 Span-level Annotations generate responses to questions asked on

the Reddit platform, as shown in Listing 1.
In Table 6, we present the distribution of errors
annotated at different span-levels (phrase, sentence 5Interpretation of agreement follows Wong et al. (2021)

20450

Answer length



much comprehensive
analogy find well due

part
make

provides important
explanation

like concise contains addresses
clearly data

used understand
mentions information

example
correct less

better points
relevant complete

factually concept selected
explains

think false
easier

good while
prefer gives

Figure 5: Distribution of the top 50 most common words mentioned by our expert annotators in their overall answer
justifications. The size and color of the bubble represent the word frequency and importance, respectively. The
green and orange colors denote the important evaluated and non-evaluated aspects, respectively, while blue depicts
the generic terms used in answer justifications.

We use the default generation parameters f"""Your task is to answer a question

in OpenAI API with temperature=0.1 and ↩→ by providing a clear and concise
↩→ explanation of a complex concept in

max_tokens=1.5*(human_answer_length). We ↩→ a way that is accessible for
specifically instruct the model to generate a ↩→ laypeople. The question was posted

response of length similar to the corresponding ↩→ on the Reddit forum Explain Like
↩→ I'm Five (r/explainlikeimfive).

human response on Reddit to compare model- ↩→ Please keep in mind that the
generated and human-written answers fairly on our ↩→ question is not literally meant for

defined evaluation criteria. ↩→ 5-year-olds, so you should not
↩→ answer the question in a way that
↩→ you are talking to a child. Your

B.2 Feedback Model ↩→ answer should be around
↩→ {human_answer_length} words and

We use expert error annotations for the complete- ↩→ should break down the concept into
ness aspect from our HQ2A dataset and train the ↩→ understandable parts, providing

feedback model for 5 epochs with a learning rate ↩→ relevant examples or analogies
↩→ where appropriate. You should also

2𝑒 − 5 and a sequence length of 1024. In List- ↩→ aim to make your explanation easy
ing 2, we show an example prompt used to train ↩→ to follow, using clear and concise

our feedback model. Given an instruction and in- ↩→ language throughout. Your answer
↩→ should maintain accuracy and

put question-answer, the output is a sentence-level ↩→ clarity. When appropriate, you can
prediction of answer completeness with detailed ↩→ start with one sentence summarizing

↩→ the main idea of the answer.
justifications.

There are clear patterns of how humans assess Question: {question}
incomplete answers, which the model can learn

Answer (around {human_answer_length}
from our training data. We explain them below, ↩→ words):
along with examples from our annotated dataset: """

1. Missing explanation of key concepts in an-
swer. These refer to concepts that are intro- Listing 1: Zero-shot prompt for GPT-4 to generate long-

form answers to questions asked on the ELI5 subreddit
duced in the answer but fail to explain it prop- on the reddit platform.
erly, assuming the reader already knows about
it.
Example: picture more crisp? You would think the reso-
Q: How does rendering a video game resolu- lution is already "maxed out", how does this
tion above your monitor resolution make the improve things?

20451



A: It’s called supersampling and basically A: There isn’t any energy loss. It’s conserved.
gives the computer more options for what to There is a kinetic energy loss because, in most
render for any given pixel. If you "render" collisions, there’s heat, sound, and (often) dis-
at a higher resolution so that each final pixel tortion of the colliding objects. The energy
is 4 pixels in the supersample then the com- changed forms to some that aren’t kinetic, so
puter gets 4 reference points for what color naturally you’ve got less kinetic energy after
that pixel could be instead of just one. [...] than before. Your second equation (vf2=...) is
Comment: Supersampling is not explained just conservation of momentum. This doesn’t
clearly in this answer. looks like it’s an energy question.

2. Failure to Address All Parts of the Ques- Comment: The first sentence says "There

tion. The answer answers only a part of the isn’t any energy loss. It’s conserved." But

question. immediately after, the answer states "There is
a kinetic energy loss..." without making a clear

Example: distinction between total energy conservation
Q: Why can’t spam call centers be automat- and kinetic energy loss.
ically shut down? Additionally, why can’t
spam calls be automatically blocked, and why 4. Lack of examples to provide more clarity.
is nobody really doing a whole lot about it? It Incomplete answers may lack references or
seems like this is a problem that they would examples to provide clarity to the reader.
have come up with a solution for by now. Example:
A: Spam call centers can’t be automatically Q: How come a CPU can function without
shut down because they are often located any driver updates whereas a GPU needs one
in countries with weak regulation and they every month or so for stability?
use advanced techniques to hide their iden- A: The eli5 answer is that you do run updates
tity, like caller id spoofing. Blocking spam for your CPU, just don’t notice that because
calls is challenging because these callers use they are packaged into stuff like iOS updates
ever-changing phone numbers, making it dif- or windows updates. Operating systems have
ficult to maintain an updated block list. While a thing called “kernel” that can be seen as
there are some efforts to combat spam calls, the driver of your CPU (yes yes I know is
such as telecom companies implementing call- not a perfect analogy but this is eli5) and that
filtering systems and governments enacting is updated regularly by windows/mac/linux
regulations, the issue is deeply rooted in the operating systems.
economic incentive for spam callers and the
complexities in tracking them down. Ulti- Comment: It doesn’t mention any example
mately, tackling spam calls requires interna- of such an update or list any type of such
tional cooperation and continuous technology update to give a clearer picture of the event it
advancements. is describing.

Comment: This answer is incomplete be- 5. Insufficient justification for a claim. Ideas/-
cause it does not fully answer parts of the claims without backing them up with evidence
question but only hints at them, such as “Why or explanations.
is nobody really doing a whole lot about it?” Example:
and “Why hasn’t a solution been found by
now?”. Q: If most electronic appliances’ efficiency

losses are through heat, does that mean that
3. Unfinished sentences or the lack of logical electric heaters are 100% efficient?

flow. Sometimes, a sentence in the answer
may be left unfinished or lacks a clear, logical A: Yes, electric heaters convert 100% of the

flow, making it hard to understand. power that they consume into heat. So they
have an efficiency of 100%. Heat pumps move

Example: heat from one area (outside your house) to
Q: How can a collision cause a loss of energy? another area (inside your house) the amount of
Even if friction and energy loss is ignored? heat they move is typically about 3 times more

20452



than the power they consume. So the in terms B.3 Refinement Model
of energy-to-heat efficiency, they are 300%+ As detailed in §4.2, the refinement model uses
efficient. But thermodynamically they are not coarse-grained feedback (IMPROVE and GENERIC)
“creating” heat from nothing. So heat pumps and fine-grained feedback from the learned error
are not perpetual motion machines, they don’t detection model to refine input answers. We list the
break any of the laws of thermodynamics. prompts used for IMPROVE, GENERIC and incorpo-
Comment: The answer lacks sufficient jus- rating fine-grained feedback in Listing 3, Listing 4
tification for the claim that electric heaters and Listing 5, respectively.
are 100% efficient. More information about
the mechanisms it uses to achieve that 100% f"""

Answer the following question:
efficiency would make the answer more com- ↩→ "{question}"
plete. Your answer is: "{answer}".

Please improve your answer.
Your improved answer:

f"""### Instruction:
When given a question and answer """
↩→ statements, evaluate whether each
↩→ given statement provides sufficient
↩→ information for answering the
↩→ question. Listing 3: Zero-shot prompt for LLaMA2-13B-chat
Use the '[Incomplete]' tag to indicate model to refine long-form answers without feedback
↩→ answer incompleteness, and from the error detection model (IMPROVE).
↩→ '[Complete]' tag to indicate
↩→ completeness, with reasons.
Please note that the answer can have
↩→ single, multiple or no incomplete f"""

↩→ statements. Answer the following question:
↩→ "{question}"

### Input: Your answer is: "{answer}".
Question: Can anyone explain the The answer is not complete.

↩→ differences between copyright and Please improve your answer.

↩→ trademark? Your improved answer:

Answer: 1. A trademark protects a
↩→ brand's symbol or logo. """

2. A copyright protects content.
3. So the ac/dc logo with the lightning
↩→ bolt would be trademarked. Listing 4: Zero-shot prompt for LLaMA2-13B-chat
4. The music and lyrics to model to refine long-form answers with generic feed-
↩→ thunderstruck would be copyrighted. back (GENERIC).
5. Edit: eli10 addendum: just to be
↩→ clear, the content of a copyright
↩→ can also be an image.
6. So the album cover to C Mitigating Errors with Preference
↩→ thunderstruck's album, razor's Optimization
↩→ edge, would be copyrighted because
↩→ it is artistic content owned by While language models acquire large amounts of
↩→ someone, but doesn't identify ac/dc
↩→ as a whole. world knowledge and strong reasoning skills from

unsupervised training over massive web corpora,
### Response: 1. [Complete] aligning them with human expectations is often
2. [Incomplete] Reasons: The answer
↩→ fails to mention the broader scope hard. Model alignment techniques like direct pref-
↩→ of copyright protection, which erence optimization (DPO) (Rafailov et al., 2023)
↩→ includes creative works beyond just
↩→ allow us to directly use preference data to optimize

music and lyrics.
3. [Complete] the language model by casting the RL-based objec-
4. [Complete] tive used by existing RLHF methods to an objective
5. [Complete]
6. [Complete] that can be directly optimized via a simple binary
""" cross-entropy loss. This simplifies the process of

refining LLMs greatly. The following paragraphs
detail how we use DPO to reduce LLM errors.

Listing 2: An example prompt used for training
LLaMA2-13B model for error feedback. Implementation details. We model data from

HQ2A as a preference dataset where every question

20453



f""" Specifically, we use the LLaMA-7B trained ver-
Answer the following question: sion of TigerScore, which highly correlates with
↩→ "{question}"
Your answer is: "{answer}". humans for error detection in LFQA tasks (Jiang
The answer is not complete because: et al., 2023b). We also measure the factual cor-
"{reason}". rectness of the generated answers using sample-
Please improve your answer.
Your improved answer: based consistency metrics (Manakul et al., 2023).

Following their approach, we zero-shot prompt a
""" LLaMA-13B-chat model to check if 𝑖𝑡ℎ sentence
# reasons are given as: in the original answer is supported by the sampled
# 1. Reason 1 answer 𝑆𝑛 and return a score 𝑥𝑛𝑖 using the map-
# 2. Reason 2
# ... ping: {"Yes: 1.0", "No: 0.0", "N/A: 0.5"}. The

final consistency score is then calculated as:

Listing 5: Zero-shot prompt for LLaMA2-13B-chat 𝑁
1 ∑︁

model to refine long-form answers with error feedback 𝑆𝑃𝑟𝑜𝑚𝑝𝑡 (𝑖) = 𝑥𝑛
𝑁 𝑖

from the error detection model. 𝑛=1

D Training, Infrastructure and Runtime
has a chosen and a rejected response selected by
expert annotators based on the given evaluation cri- We use a server with 8 NVIDIA A100 Tensor Core
teria. Using this dataset, we fine-tune the LLaMA2- GPUs, each with 80GB VRAM, to run all our
7B-chat (Touvron et al., 2023b) and Mistral-7B- experiments. Each experiment required, at most,
Instruct-v0.1 (Jiang et al., 2023a) models with two A100 GPUs. Fine-tuning the LLaMA2-13B
the DPO algorithm. We use 𝑏𝑎𝑡𝑐ℎ_𝑠𝑖𝑧𝑒 = 16, feedback model took 6 hours on 2 A100 GPUs
𝑤𝑎𝑟𝑚𝑢𝑝_𝑟𝑎𝑡𝑖𝑜 = 0.1, 𝑙𝑒𝑎𝑟𝑛𝑖𝑛𝑔_𝑟𝑎𝑡𝑒 = 2𝑒 − 5, using our HQ2A dataset. LoRA fine-tuning of
𝑛𝑢𝑚_𝑒𝑝𝑜𝑐ℎ𝑠 = 5, 𝑏𝑒𝑡𝑎 = 0.1, and 𝑚𝑎𝑥_𝑙𝑒𝑛𝑔𝑡ℎ = the LLaMA2-13B-chat refinement model took 2

1024 for training the models. hours on a single A100 GPU using the prefer-
Due to compute limitations, we train Llama2- ence data from HQ2A. Refining answers with our

13B-chat model on our preference dataset using ERROR-INFORMED REFINEMENT approach took
LoRA (Hu et al., 2022). We use the following 0.5, 3, and 23 hours for the HQ2A, ASQA, and
training parameters: 𝑟 = 256, 𝑎𝑙 𝑝ℎ𝑎 = 128, ELI5 datasets, respectively, on a single A100 GPU.
𝑙𝑜𝑟𝑎_𝑑𝑟𝑜𝑝𝑜𝑢𝑡 = 0.05, 𝑙𝑒𝑎𝑟𝑛𝑖𝑛𝑔_𝑟𝑎𝑡𝑒 = 5𝑒 − 5, The evaluation of the refined answers with Tiger-
𝑏𝑒𝑡𝑎 = 0.1, 𝑚𝑎𝑥_𝑙𝑒𝑛𝑔𝑡ℎ = 1024 and train the Score (LLaMA-7B) utilized the VLLM inference
model for 5 epochs. library (Kwon et al., 2023) and took approximately

1, 15, and 30 minutes for HQ2A, ASQA, and ELI5
Datasets & Evaluation Metrics. We experiment datasets, respectively, on a single A100 GPU.
with three datasets: HQ2A, ASQA (Stelmakh et al.,
2022), and ELI5 (Fan et al., 2019). HQ2A dataset E Additional Results
consists of 698 high-quality long-form question-
answer pairs split into train (80%), dev (10%), and E.1 Aligning LLMs
test (10%) sets. The ASQA dataset consists of Table 7 shows the results for training language mod-
6K ambiguous factoid questions with long-form els with DPO using our collected preference anno-
answers synthesized from multiple sources to re- tations. Our preference-tuned models outperform
solve the ambiguities. ELI5 consists of 270K long- the strong baseline models and reduce error gen-
form answers covering general topics from the erations in all the evaluation settings except the
subreddits "explainlikeimfive", "askscience", and LLaMA model on the ASQA dataset. We hypoth-
"AskHistorians" on the Reddit platform. esize that this is due to the ambiguous nature of

We report the quality of the generated long-form questions in the ASQA dataset that can have multi-
answers using TigerScore (Jiang et al., 2023b), a ple correct answers.
trained reference-free evaluation metric to pinpoint We also observe that the models become more
mistakes in the LLM-generated text. TigerScore robust and generate more consistent responses after
detects errors in the input text and assigns an error preference-tuning. The only exception is the Mis-
score based on the severity of the error detected. tral model on our held-out test set, which has lower

20454



Dataset TIGERScore
(# samples) Instruct Model SelfCheck

% Error samples (↓) Error score (↓) Consistency (↓)

LLaMA2-7B 18.57 ± 0.00 0.60 ± 0.00 0.166 ± 0.014
LLaMA2-7B + DPO 15.71 ± 0.00 0.66 ± 0.00 0.162 ± 0.015

HQ2A (70)
Mistral-7B 20.00 ± 0.00 0.57 ± 0.00 0.266 ± 0.011
Mistral-7B + DPO 17.14 ± 0.00 0.54 ± 0.00 0.285 ± 0.011

LLaMA2-7B 26.58 ± 1.49 0.86 ± 0.06 0.187 ± 0.014
LLaMA2-7B + DPO 28.41 ± 1.06 0.89 ± 0.02 0.178 ± 0.006

ASQA (948)
Mistral-7B 62.09 ± 0.35 2.08 ± 0.01 0.578 ± 0.003
Mistral-7B + DPO 60.80 ± 0.56 2.03 ± 0.01 0.555 ± 0.008

LLaMA2-7B 9.93 ± 1.05 0.32 ± 0.04 0.133 ± 0.001
ELI5_GENERAL LLaMA2-7B + DPO 9.33 ± 0.66 0.29 ± 0.03 0.130 ± 0.004
(1000) Mistral-7B 29.97 ± 0.97 0.90 ± 0.04 0.327 ± 0.003

Mistral-7B + DPO 22.77 ± 1.03 0.72 ± 0.03 0.319 ± 0.011

LLaMA2-7B 9.47 ± 0.47 0.31 ± 0.02 0.137 ± 0.003
ELI5_SCIENCE LLaMA2-7B + DPO 9.47 ± 0.76 0.30 ± 0.00 0.139 ± 0.004
(1000) Mistral-7B 34.10 ± 0.94 1.07 ± 0.02 0.320 ± 0.004

Mistral-7B + DPO 29.03 ± 1.51 0.95 ± 0.04 0.297 ± 0.010

LLaMA2-7B 9.63 ± 0.59 0.30 ± 0.02 0.188 ± 0.005
ELI5_HISTORY LLaMA2-7B + DPO 7.60 ± 0.08 0.22 ± 0.01 0.189 ± 0.005
(1000) Mistral-7B 26.23 ± 0.38 0.79 ± 0.02 0.363 ± 0.016

Mistral-7B + DPO 22.17 ± 1.31 0.69 ± 0.04 0.345 ± 0.013

Table 7: Results of aligning LLMs with DPO using our collected answer preference data. We measure the errors
using Tigerscore and the consistency of model outputs using SelfCheckGPT. Reported results are averages over
three iterations with standard deviations. The best scores are marked in bold.

response consistency. We believe this is likely due respectively. Similar to the observations in §5.2,
to the conservative nature of DPO-trained models we notice that inadequate feedback deteriorates the
wherein, during sampling, it can refrain from an- quality of generation.
swering a question in some cases and not in others, When using LLaMA3-8B-Instruct as the refine-
leading to a lower consistency score. ment model, the direct prompting (ZERO-SHOT)

and refining without detailed feedback (IMPROVE)
E.2 EIR with DPO approaches improve answer quality over the BASE-
In Table 8, we present the quality of answers re- LINE (original answers from the dataset) on all the
fined using different types of feedback (coarse- and datasets, except ASQA, where the ZERO-SHOT ap-
fine-grained), alongside the BASELINE answers. proach generates lower quality answers than BASE-
Additionally, we include the results for answers LINE, likely due to the ambiguous nature of the
refined with the DPO-aligned model. While the questions in the ASQA dataset. On the contrary,
DPO-aligned refinement model does not outper- prompting with more targeted feedback (GENERIC)
form the vanilla refinement model in reducing the consistently outperforms the BASELINE, ZERO-
overall number of error samples, it achieves the SHOT, and IMPROVE approaches, generating better
best error scores on ASQA and ELI5. This sug- quality LFQA answers and giving the best scores
gests that the DPO optimization is still effective in on HQ2A. Furthermore, providing fine-grained
correcting major errors to some extent. feedback from our error detection model (EIR)

outperforms coarse-grained feedback on ASQA
E.3 Fine- vs. Coarse-grained Feedback and ELI5 datasets, reducing error samples and er-
In Table 9 and Table 10, we show the results on ror scores by ~8% and ~Δ68%, respectively, and
the quality of answers generated with zero-shot improving F1 scores by ~11% on average.
prompting (ZERO-SHOT) as well as answers re- When using Mistral-7B-Instruct-v0.3 as the re-
fined using coarse (IMPROVE and GENERIC) and finement model, the approach to refine answers
fine-grained (EIR) feedback, using the LLaMA3- without detailed feedback (IMPROVE) improves an-
8B-Instruct and Mistral-7B-Instruct-v0.3 models, swer quality over the BASELINE, ZERO-SHOT, and

20455



TIGERScore Error Correction
Dataset Approach

% Error samples (↓) Error score (↓) Precision (↑) Recall (↑) F1 (↑)

Human feedback 2.61 ± 0.92 0.09 ± 0.01 0.86 ± 0.04 1.00 ± 0.00 0.94 ± 0.02
HQ2A

Baseline 19.61 0.63 - - -
Improve 1.31 ± 0.92 0.05 ± 0.04 1.00 ± 0.00 0.93 ± 0.05 0.97 ± 0.02
Generic 1.31 ± 0.92 0.05 ± 0.03 0.97 ± 0.04 0.97 ± 0.05 0.97 ± 0.02
EIR (Ours) 0.65 ± 0.92 0.03 ± 0.04 0.97 ± 0.04 1.00 ± 0.00 0.98 ± 0.02
EIR w/ DPO (Ours) 4.57 ± 2.44 0.07 ± 0.02 0.90 ± 0.08 0.87 ± 0.05 0.88 ± 0.06

Baseline 34.81 1.20 - - -
ASQA

Improve 20.85 ± 1.00 0.68 ± 0.03 0.70 ± 0.02 0.71 ± 0.01 0.70 ± 0.01
Generic 18.67 ± 0.52 0.61 ± 0.01 0.72 ± 0.01 0.75 ± 0.01 0.74 ± 0.00
EIR (Ours) 16.63 ± 0.41 0.51 ± 0.02 0.73 ± 0.00 0.82 ± 0.02 0.77 ± 0.01
EIR w/ DPO (Ours) 22.61 ± 0.26 0.45 ± 0.01 0.64 ± 0.00 0.77 ± 0.01 0.71 ± 0.00

Baseline 22.93 0.82 - - -
ELI5

Improve 10.05 ± 0.18 0.36 ± 0.02 0.75 ± 0.00 0.86 ± 0.00 0.80 ± 0.00
Generic 6.06 ± 0.23 0.22 ± 0.01 0.84 ± 0.01 0.91 ± 0.00 0.87 ± 0.00
EIR (Ours) 3.81 ± 0.30 0.13 ± 0.01 0.88 ± 0.01 0.96 ± 0.01 0.92 ± 0.01
EIR w/ DPO (Ours) 5.71 ± 0.25 0.13 ± 0.00 0.83 ± 0.00 0.94 ± 0.01 0.88 ± 0.00

Table 8: Results on the quality of original answers from the datasets (BASELINE), answers refined with coarse-
grained feedback (IMPROVE and GENERIC), and fine-grained feedback (EIR). Additionally, we include the results
of refinement with expert human feedback on our collected data. Reported results are averages over three iterations
with standard deviations. The best scores are marked in bold.

even the GENERIC approach, achieving the best is difficult.
scores on HQ2A. We hypothesize that this is due
to the capability of the model to understand sim-
plistic feedback instructions to improve answers,
leading to a better performance than the GENERIC
approach. In contrast, providing fine-grained feed-
back from our error detection model (EIR) outper-
forms coarse-grained feedback on ASQA and ELI5
datasets, reducing error samples and error scores
by ~2% and ~Δ27%, respectively, and improving
F1 scores by ~4% on average.

E.4 Human Evaluation

This section presents additional details of our hu-
man evaluation of the answers refined with our
Error-informed feedback approach. In Table 11,
we present the agreement of our annotators on two
evaluation metrics: comprehensiveness and overall
answer preference. The annotators strongly agree
that the refined answers are comprehensive, i.e.,
the answer contains all the required information
as asked by the question. For the overall answer
preference compared to the baseline, we observe
weak agreement between annotators, primarily due
to the low agreement value on the ASQA dataset.
We hypothesize that the annotators struggle to align
on ASQA due to the ambiguous nature of the ques-
tions in this dataset, which may have multiple cor-
rect answers, and choosing between two answers

20456



TIGERScore Error Correction
Dataset Approach

% Error samples (↓) Error score (↓) Precision (↑) Recall (↑) F1 (↑)

Human feedback 1.96 ± 0.00 0.07 ± 0.01 0.90 ± 0.01 1.00 ± 0.00 0.95 ± 0.00
HQ2A

Baseline 19.61 0.63 - - -
Zero-shotLLaMA3 17.65 ± 0.00 0.46 ± 0.00 0.53 ± 0.00 0.80 ± 0.00 0.64 ± 0.00

Improve 2.61 ± 0.92 0.04 ± 0.04 0.88 ± 0.04 1.00 ± 0.00 0.93 ± 0.02

Generic 0.00 ± 0.00 0.00 ± 0.00 1.00 ± 0.00 1.00 ± 0.00 1.00 ± 0.00

EIR (Ours) 1.30 ± 0.92 0.03 ± 0.03 0.96 ± 0.04 0.96 ± 0.05 0.96 ± 0.02

Baseline 34.81 1.20 - - -
ASQA

Zero-shotLLaMA3 42.83 ± 0.00 1.39 ± 0.00 0.41 ± 0.00 0.55 ± 0.00 0.47 ± 0.00
Improve 30.09 ± 0.53 0.82 ± 0.01 0.55 ± 0.01 0.72 ± 0.01 0.62 ± 0.01

Generic 20.92 ± 0.62 0.51 ± 0.03 0.66 ± 0.01 0.81 ± 0.01 0.72 ± 0.01

EIR (Ours) 10.16 ± 0.65 0.23 ± 0.02 0.82 ± 0.02 0.89 ± 0.01 0.85 ± 0.01

Baseline 22.93 0.82 - - -
ELI5

Zero-shotLLaMA3 3.22 ± 0.00 0.10 ± 0.00 0.91 ± 0.00 0.96 ± 0.00 0.93 ± 0.00

Improve 3.05 ± 0.14 0.09 ± 0.01 0.90 ± 0.01 0.97 ± 0.00 0.93 ± 0.01

Generic 2.70 ± 0.18 0.06 ± 0.01 0.91 ± 0.01 0.97 ± 0.00 0.94 ± 0.00

EIR (Ours) 0.99 ± 0.06 0.02 ± 0.01 0.96 ± 0.01 0.99 ± 0.00 0.97 ± 0.01

Table 9: Results on the quality of original answers from the datasets (BASELINE), answers from 0-shot prompting
LLaMA3-8B-Instruct (ZERO-SHOT), answers refined with coarse-grained feedback (IMPROVE and GENERIC), and
fine-grained feedback (EIR) using LLaMA3-8B-Instruct refinement model. Additionally, we include the results of
refinement with expert human feedback on our collected data. Reported results are averages over three iterations
with standard deviations. he best results are in bold green and the second-best results are in orange .

TIGERScore Error Correction
Dataset Approach

% Error samples (↓) Error score (↓) Precision (↑) Recall (↑) F1 (↑)

HQ2 Human feedback 1.96 ± 0.00 0.07 ± 0.01 0.90 ± 0.01 1.00 ± 0.00 0.95 ± 0.00
A

Baseline 19.61 0.63 - - -
Zero-shotMistral 3.92 ± 0.00 0.16 ± 0.00 0.83 ± 0.00 1.00 ± 0.00 0.91 ± 0.00

Improve 1.30 ± 1.85 0.03 ± 0.05 0.96 ± 0.05 0.96 ± 0.05 0.96 ± 0.05

Generic 1.96 ± 0.00 0.05 ± 0.03 0.90 ± 0.01 1.00 ± 0.00 0.95 ± 0.00
EIR (Ours) 4.57 ± 1.85 0.15 ± 0.05 0.85 ± 0.06 0.93 ± 0.09 0.88 ± 0.05

Baseline 34.81 1.20 - - -
ASQA

Zero-shotMistral 39.35 ± 0.00 1.24 ± 0.00 0.45 ± 0.00 0.58 ± 0.00 0.51 ± 0.00

Improve 13.53 ± 0.44 0.32 ± 0.03 0.77 ± 0.01 0.86 ± 0.01 0.81 ± 0.01
Generic 15.85 ± 1.05 0.40 ± 0.03 0.74 ± 0.02 0.83 ± 0.01 0.78 ± 0.01

EIR (Ours) 10.72 ± 0.96 0.23 ± 0.02 0.81 ± 0.02 0.90 ± 0.01 0.85 ± 0.01

Baseline 22.93 0.82 - - -
ELI5

Zero-shotMistral 7.91 ± 0.00 0.25 ± 0.00 0.79 ± 0.00 0.90 ± 0.00 0.84 ± 0.00

Improve 3.22 ± 0.16 0.09 ± 0.01 0.89 ± 0.01 0.96 ± 0.01 0.93 ± 0.00

Generic 3.81 ± 0.15 0.11 ± 0.01 0.88 ± 0.01 0.96 ± 0.01 0.92 ± 0.00

EIR (Ours) 3.02 ± 0.19 0.08 ± 0.01 0.90 ± 0.01 0.97 ± 0.01 0.94 ± 0.00

Table 10: Results on the quality of original answers from the datasets (BASELINE), answers from 0-shot prompting
Mistral-7B-Instruct-v0.3 (ZERO-SHOT), answers refined with coarse-grained feedback (IMPROVE and GENERIC),
and fine-grained feedback (EIR) using Mistral-7B-Instruct-v0.3 refinement model. Additionally, we include the
results of refinement with expert human feedback on our collected data. Reported results are averages over three
iterations with standard deviations. he best results are in bold green and the second-best results are in orange .

20457



Dataset Comprehensiveness (↑) Preference (↑)

HQ2A 0.70 0.31
ASQA 0.86 0.02
ELI5 0.92 0.61

Average 0.83 0.31

Table 11: Agreement of annotators on the comprehen-
siveness and preference of refined answers over the
baseline answers from three datasets.

20458



Aspect Answer Original Annotation Expert Justification Sentence-level Annotation
Question

What are the pros/cons The main advantage of borrowing This answer is missing the disad- 1. [Incomplete] Reasons: This
of borrowing money money from a bank (a mortgage) vantages of getting a mortgage and answer is missing [...]

Completeness from the bank vs pay- to buy a house is that it allows paying in cash. It could mention 2. [Incomplete] Reasons: This
ing cash when buying a you to purchase a property without how getting a mortgage means answer is missing [...]
house? And why would having all the cash up front. This you will have to pay interest, as
it ever be a good idea to enables people to become home- well as any mortgage fees (such as ...
borrow if you can pay owners earlier in life and poten- arrangement fees or valuation fees).
cash and pay no interest tially benefit from the appreciation It could also discuss how your home
to the bank? of the home’s value. Paying a mort- could be put at risk if you are unable 8. [Incomplete] Reasons: This

gage also helps build credit history, to keep up with the repayments answer is missing [...]
which can be beneficial for obtain- since a mortgage is secured against
ing future loans or credit cards. On the value of your property. In
the other hand, paying cash for a terms of paying in cash, the answer
house has the advantage of no in- could explain that this will narrow
terest costs, which can save a sub- your investment portfolio, thereby
stantial amount of money over time. missing the opportunity to invest in
Cash buyers may also have more other assets that could increase your
negotiating power, as they are not wealth over time.
reliant on bank approval and can Source: (Heming,2022)
close the deal quickly. In certain sit- https://www.moneysupermarket.com/
uations, it can be better to borrow mortgages/advantages-and-
money even if you have the cash. disadvantages/
This is because investing the cash
into diversified investments (stocks,
bonds, etc. ) may provide better re-
turns than paying off the mortgage
early, although it comes with some
level of risk. Additionally, having
cash reserves can provide financial
flexibility for emergencies or future
opportunities.

Why do people often Diet sodas are often considered just Overall health is a combination of 1. [Complete]
say diet sodas are just as as bad or worse than regular so- nutrition and exercise, artificial in- 2. [Complete]

Completeness bad or worse than regu- das because they contain artificial gredients do not necessarily con-
lar sodas? sweeteners instead of sugar. These tribute to poor health. ...

sweeteners, like aspartame or su-
cralose, can have negative effects
on the body. For example, they may 6. [Incomplete] Reasons: Overall
confuse the body’s natural ability health is a [...]
to regulate calorie intake by trick- 7. [Complete]
ing it into thinking it’s consuming
real sugar. This can lead to overeat-
ing and weight gain. Additionally,
some studies have suggested that ar-
tificial sweeteners might negatively
impact gut bacteria, potentially lead-
ing to health issues. While diet so-
das have fewer calories than regular
sodas, they can still contribute to
poor overall health due to these arti-
ficial ingredients. Therefore, many
people believe they are no better
than, or even worse than, regular
sodas.

Table 12: Examples of transforming expert annotations for completeness to sentence-level annotations for training
the feedback model.

20459



F Annotation Guidelines
We have previously described our data collection setup in §3.5. This section provides additional details on
the annotation interface, detailed task instructions, and annotation procedure.

F.1 Annotation Interface
In Figure 6, we show the interface for collecting expert error annotations on LFQA answers. For every
question, experts see a human-written and model-generated answer (randomized order). Our expert
annotators must select the evaluation layer (top right) and highlight the error span in the question or
answer, giving justifications with web references, wherever applicable. After annotating for all the
evaluation criteria, experts judge the better answer and mark it in the left pane, giving reasons for their
preference.

Figure 6: Screenshot of annotation interface for collecting expert error annotations on LFQA answers.

F.2 Task Instructions
We provide experts with detailed task instructions for evaluating answers according to the defined
evaluation criteria. We go through every evaluation aspect in depth, defining it and giving annotation
examples for clarification, as detailed in the next paragraphs.

1) Question Misconception. You should select a span of text in the question that contains a misconcep-
tion or false assumption. The question is repeated twice. You only need to select the span in one repetition.
If you select such spans, we would like you to indicate in your reason (obligatorily):

• whether the answers reject or correct the misconception/false assumption,

• if no answer rejects/corrects it, please explain in your reason why that is a misconception/false
assumption (preferably with references).

Example:
Question: Why is it so important for humans to have a balanced nutrition but not for animals? Most
animals have a fairly simple diet, carnivores eat only meat their whole life, cows eat exclusively grass etc.

20460



So why are human bodies so picky and need a balance of protein, fat, carbs etc from different sources to
perform well?

2) Factuality. You should select a span of text in the answers that is factually incorrect. If you select
such spans, we would like you to (obligatorily):

• preferably give references (e.g., credible websites, academic papers, or books) that show the content
is factually wrong, or

• give examples that show the content is factually wrong.

Example:
Question: Why is it so important for humans to have a balanced nutrition but not for animals? Most
animals have a fairly simple diet, carnivores eat only meat their whole life, cows eat exclusively grass etc.
So why are human bodies so picky and need a balance of protein, fat, carbs etc from different sources to
perform well?
Answer: Animals generally have a simpler diet than humans. For example, carnivores only eat meat, while
cows only eat grass...
Reason: This is a reductionist view of animal nutrition as it doesn’t consider how animals have evolved
and the complexities of the food chain. For example, lions are carnivores that only eat meat but they eat
the stomach of zebras that contain grass/plants and are able to digest it.

3) Relevance. You should select a span of text in the answers that is irrelevant to answering the question.
Removing such content should not affect the overall quality of an answer. If you select such spans, we
would like you to (obligatorily):

• explain why the selected text is not relevant to answering the question.

Example:
Question: What is happening when you get migraines that cause you to lose part of your vision for a short
time?
Answer: My wife gets these. An ocular migraine is a condition where the blood vessels in the optic nerve
at the back of your eye tighten and swell, resulting in various visual distortions. While classic migraines
usually result in intense headaches, sensitivity to light and loud sounds, or nausea, ocular migraines are
not necessarily painful.
Reason: Answer contains irrelevant information (writer’s wife having them, migraine may not be painful).
The person’s wife’s personal health condition doesn’t provide useful information to the question, and the
question doesn’t ask about whether ocular migraines are painful or not.

4) Completeness. You should: (a) select a span of text in the answer that does not offer enough details,
or (b) select the label Answer 1 or Answer 2 if some relevant information that should be included in the
answer is missing. If you select such spans, we would like you to (obligatorily):

• offer the details or relevant information that you think should be included. References from credible
sources is encouraged.

Example:
Question: Why does alcohol make your throat or stomach feel warm when drinking?
Answer: There are a few reasons why alcohol might make your throat or stomach feel warm. first, alcohol
is a solvent, which means it can dissolve other substances. when you drink alcohol, it can break down the
barrier between your stomach and your throat, causing a burning sensation. second, alcohol can irritate
the lining of your stomach, causing inflammation. this can also lead to a burning feeling. finally, when
you drink alcohol, your blood vessels dilate, or widen. this increased blood flow can cause a feeling of
warmth.
Reason: The answer should give more details on what the barrier is. [Offer relevant information based on
your knowledge, for example, what the barrier is.]

20461



5) References/example/analogy. You should select a span of text in the answer that is examples/analo-
gies or a reference to a external credible source (e.g., websites, papers, or books). If you select such spans,
we would like you to (obligatorily):

• indicate whether the example/analogy/credible source is helpful, and

• give a reason on why it is helpful/not helpful.

Example:
Question: How does a speaker vibrate at multiple frequencies simultaneously to deliver sounds to our
ears? I’ll try and explain what I mean.. say a song is playing - how do the vocals, drums, guitars etc which
all have different frequencies (aka a plate is moving back & forth at a rate to deliver these sound waves)
play at the same time? Surely the plate can’t vibrate to deliver two or more frequencies at once?
Answer: Imagine an ocean with a consistent wave. It flows up and down, with equal distance between
the two waves at any time. Now imagine I push a larger, shorter wave into this ocean. The two waves
will collide, resulting in some new wave pattern. This new wave pattern is a combination of those two
waves. Speakers work similarly. If I combine two sound waves, I get a new combination wave that sounds
different.
Reason: I like the analogy with the ocean waves, and due to how visual the explanation is it is easier to
understand in my opinion.

Answer Preference. Based on the five criteria you have went through, please weight all good and bad
points of each answer and choose the one that is better overall. Writing a motivation to support your
choice is obligatory.

1. When writing your motivation, please refer to the five layers of evaluation.

2. If there are other aspects you used to make your decision but are not in the evaluation layers, please
mention them in the reason

3. If you have quotations from the answers, please indicate which answer are the quotations from.

4. Here are some aspects for you to consider (not obligatorily):
• Nice example/analogy, to the point, generic, concise, informative, useful, well structured, easy

to follow ...

Overall Requirement. The overall task requirements are summarized below. Please read them carefully
to avoid redoing the task.

1. You have to highlight spans in both question answers for these aspects and give reason why you
highlight a span for an aspect.

2. Mark as many spans as necessary.

3. Please be objective in your reasons and avoid using phrases like “I believe” or “I think”.

4. Your reasons should be informative and succinct.

5. Please use declarative sentences and avoid using questions in your reasons.

6. Products like ChatGPT or BARD are absolutely not allowed.

F.3 Annotation Procedure
The expert annotators spend around 15-20 minutes per question, highlighting the demanding nature of
this task. We accordingly pay £10/hour and provide a bonus of £10 for good-quality annotations, resulting
in a total cost of £3000 to collect expert judgments for 698 questions. The annotators understand that we
will use their annotated data for research purposes. We show a screenshot of an expert annotated answer
in Figure 7.

20462



Figure 7: Screenshot of an expert annotated answer on the INCEpTION platform.

20463



Table 13: Additional examples of expert annotated errors in long-form answers based on the defined evaluation
criteria. The answers in green are expert-preferred answers. The overall answer preference justifications are not
shown here.

Aspect Question Answer A Answer B Expert Justification

How is GPS free? (human) GPS "receivers" are just ra- (model) GPS is free because it’s a Although GPS is a free service,
GPS has made a ma- dios that listen to broadcasts by spe- public service provided by the US made accessible to civilians for

Question jor impact on our cific satellites, and then use some government through a network of free by Ronald Reagan, America’s
Misconception world. How is it math to calculate the location. There satellites. Your phone or device re- former president at the time, it is

a free service that is no back and forth data transmis- ceives signals from these satellites not entirely without cost, as U.S.
anyone with a phone sion at all. So there is no capacity to determine its location. Compa- taxpayers fund it. Therefore, if you
can access? How is limit and no extra costs for more nies make profits by offering addi- live and work in the U.S. and use
it profitable for com- users. The us government created tional services or applications that a smartphone, you do not receive
panies to offer ser- GPS as a military program. It would use GPS data, such as navigational GPS on your phone for free, even
vices like navigation likely still be maintained even if no apps or ads based on your location. though you are not directly paying
without subscription civilians used it, just like it was be- These companies don’t need to pay for it; you are paying indirectly
fees or ads? fore it was opened up to the public. for access to GPS data because the through taxes. On the other hand,

US government maintains and funds for people living outside of the U.S.,
this infrastructure. GPS might be available on their

smartphones at no additional charge,
but they often need to pay indirectly
through internet service fees before
they can use it.
Source1:
https://www.quora.com/How-
is-GPS-sustained-as-a-free-service
Source2:
https://www.gps.gov/policy/funding/

If movies run at 24 (human) U/dragoniel is right about (model) Movies appear smooth at This is a misconception. Not all
Question fps, why do games motion blur, but the more important 24 frames per second (fps) due to games look bad on FPS below 60.
Misconception look so bad unless answer is that movies very rarely motion blur created by cameras cap- In fact, most games run smoothly

they run at at least 60 move the camera, they certainly turing the natural blur of moving ob- between 30 and 60 FPS, although
fps? don’t spin it 180 degrees in a frac- jects. Video games lack this natu- some games will not work smoothly

tion of a second. If they did every- ral motion blur as they consist of on fps below 60.
thing in the shot would be a blurry sharp, static images. To compensate, Source:
mess. A whole load of thought goes games need higher frame rates, like https://www.avg.com/en/signal/9-
into how you get the shot you want 60 fps, to create smoother transitions ways-boost-gaming-rig
without too much camera motion between static images, and reduce
and all the bullet time stuff from distractions caused by choppiness or
the matrix was done with many still sudden changes while playing. Ad-
cameras taking a single photo, not ditionally, games involve frequent
moving a camera on a rocket sled. interactions with controllers, requir-

ing faster feedback to feel more re-
sponsive, which makes higher frame
rates even more essential for a good
gaming experience.

Why can you sleep (human) Your body produces a (model) During sleep, your body The urine production is decreased
through the night hormone called (vasopressin) an- produces less urine [...] Addition- due to the hormone, not addition-

Factuality without going to the tidiuretic hormone, or adh, which ally, the hormone vasopressin helps ally. The more concentrated urine
bathroom? causes the body to produce less to reduce urine production at night. is because you cannot drink while

urine at night. It’s the reason [...] This combination of decreased [...] sleeping.

Why hasn’t there (human) There are lots of different (model) Ticketmaster’s dominance Ticketmaster’s market share in-
been anyone to come ticketing companies. Dozens, possi- is due to exclusive contracts with creased from 66% to 70% between

Factuality out as a competitor bly hundreds. Ticketmaster however venues and promoters, giving them 2021 and 2022. Therefore, smaller
to ticketmaster? is locked in to the biggest venues control over ticket sales. Competi- ticketing companies have so far

that feature the biggest artists, either tors struggle to break into the mar- been unable to challenge Ticketmas-
because they have exclusive con- ket because they lack access to these ter’s monopoly.
tracts or they outright own the venue. popular events. However, some Source:
If you look at smaller venues than smaller companies like eventbrite https://www.usesignhouse.com/blog/
stadiums and arenas they often use and axs have been growing, tar- ticketmaster-stats
different ticketing companies. geting niche markets and smaller

venues to challenge ticketmaster’s
monopoly.

Continued on next page

20464



Aspect Question Answer A Answer B Expert Justification

How do publishers (human) Some publishers try to only (model) Ebook publishers use sev- This does not tell us how publish-
of ebooks prevent publish on platforms that take com- eral methods to prevent piracy, ers prevent piracy; it only provides

Relevance piracy? plete control of the distribution chan- which mainly involve digital rights a scenario explaining why piracy
nels, file types, software and hard- management (DRM) and watermark- would not occur in books as it would
ware to make it hard for people to ing. DRM is a technology used to in visual media.
copy the ebook without permission. restrict access to and usage of copy-
Most famous of these distributors righted material, such as ebooks. In
is amazon with their kindle ebook simple terms, DRM is like a lock
services. But others are doing the that prevents unauthorized copying
same. This does however make it and sharing of ebooks. When you
harder for the customers to read the purchase an ebook, you’re usually
books unless they have the required given a key (in the form of an ac-
hardware. And it does not com- count or device authorization) to un-
pletely prevent piracy. Other pub- lock and read the book. This pre-
lishers make sure that it is easier and vents users from easily sharing the
better service to buy the book out- ebook file with others, as they will
right instead of pirating it. There is not have the necessary key to open it.
not actually a very big market for Some popular drm systems used for
pirated ebooks as there is for movies ebooks include adobe’s adept and
and TV series. So it can be hard to amazon’s kindle drm. Watermark-
find pirated versions of the books ing is another technique ebook pub-
you want, especially high quality lishers use to deter piracy. Instead of
versions. That makes the $3-10 for locking the content like drm, a dig-
an ebook directly from the publisher ital watermark embeds identifiable
a preferable deal to a lot of people. information into the ebook file. This
The people who do not want to pay information can be visible (like a
this probably would not want to buy logo or text) or invisible (embedded
the book even if they did not find in the file’s data). [...]
any pirated versions. So there is no
loss in revenue to not implement any
digital rights management.

Why do companies (human) In my experience software (model) Meta, formerly known as Adds nothing to the explanation is a
like Meta have so companies lean heavily on product Facebook, is a massive tech com- rant by the person.

Relevance many employees, and project managers. To stay com- pany that requires a large number
what do they do? petitive in tech you have to con- of employees to manage and main-

stantly be trying to innovate (at least tain its various services, products,
that’s the idea), which takes a lot and operations. [...] let’s break it
of people to come up with and plan down into main areas:1. Software
out these projects, even if many development: Meta operates numer-
never see the light of day. Beyond ous services and applications, in-
that, maintaining a tech infrastruc- cluding Facebook, Instagram, What-
ture like that is very complex„ goes sapp, and the oculus virtual reality
well beyond devs. [...] Facebook platform. Each of these services re-
also has a huge footprint in the open quires teams of software engineers,
source community, in that they ac- product managers, and designers
tively maintain many sophisticated to develop, maintain, and improve
projects they built for their products the platforms. [...] 2. Infrastruc-
that are now used by millions of ture and operations: with billions
other products, like their react frame- of active users, Meta must maintain
works. Not to mention they heavily and develop a vast infrastructure of
use other open source softwares and servers, networks, and data centers
dedicate some resources to maintain- to handle the enormous amount of
ing those as well [...] Successful data being generated, processed, and
tech companies are incredibly con- stored. [...] 3. Research and devel-
voluted and complex in my experi- opment: companies like meta are
ence. Many times there are whole always innovating and creating new
teams working on "nothing" because technologies. They require exten-
their part of the business is on its sive r&d teams that include experts
way out, or they were part of another in fields like artificial intelligence,
company that was acquired, and in virtual reality, and machine learning.
either case, someone in the middle These teams drive the development
hasn’t gotten around to trimming of cutting-edge technologies and so-
the fat/reallocating those resources. lutions for Meta’s products. [...] 4.
Source: have worked for a faang Sales and marketing: meta generates
company, other huge tech compa- a significant portion of its revenue
nies, now work as a private contrac- from advertising. [...] 5. User sup-
tor bc of how ** annoying these con- port and moderation: with billions
glomerates are to work with. of users worldwide, [...]

Continued on next page

20465



Aspect Question Answer A Answer B Expert Justification

How do pharmacies (human) General yes, pharmacies (model) Pharmacies keep a stock of The answer should specify factors
work? Do they just will keep enough of the more com- commonly prescribed medications that may affect the availability of

Completeness have every kind of monly requested medications in on hand. When you provide your medications, such as manufacturing
medication at all stock so that most prescriptions can prescription, the pharmacist checks issues, disruptions in supply, and
time? How is a be filled the same day. When that’s their inventory, measures and pack- stockouts of essential medicines
prescription ready not possible, depending on various ages the drug, and puts the proper (World Health Organization).
within an hour? Eta factors, many pharmacies may have labeling and instructions on it. If the For more information, you can
thank you everyone multiple deliveries from suppliers medication isn’t in stock, they can visit: https://www.who.int/our-
for taking the time to each week, making it possible to usually order it and have it ready in work/access-to-medicines-and-
respond! I know it order anything that isn’t in stock a short time. Efficient organization health-products
seems super obvious within a few days if it’s available and well-trained staff help facilitate
as to how it works, from the supplier. the quick turnaround for prescrip-
this was a late night tions.
thought I had and
needed to know?

What are the pros/- (human) If you can make more (model) The main advantage of bor- This answer is missing the disad-
cons of borrowing money doing something else with rowing money from a bank (a mort- vantages of getting a mortgage and

Completeness money from the your cash than using it to pay down gage) to buy a house is that it allows paying in cash. It could mention
bank vs paying your mortgage, then it’s beneficial you to purchase a property without how getting a mortgage means
cash when buying to take out a loan. It depends on having all the cash up front. This en- you will have to pay interest, as
a house? And why your credit rating what kind of inter- ables people to become homeowners well as any mortgage fees (such as
would it ever be a est you’ll get on your loan, and what earlier in life and potentially benefit arrangement fees or valuation fees).
good idea to borrow the long term stock market trends from the appreciation of the home’s It could also discuss how your home
if you can pay cash are, or if you want to buy multiple value. Paying a mortgage also helps could be put at risk if you are unable
and pay no interest properties at the same time, for ex- build credit history, which can be to keep up with the repayments
to the bank? ample. But making money in the beneficial for obtaining future loans since a mortgage is secured against

stock market is not a given, so there or credit cards. On the other hand, the value of your property. In
is risk involved in going that route. paying cash for a house has the ad- terms of paying in cash, the answer
Also, you want to have cash on hand vantage of no interest costs, which could explain that this will narrow
for possible emergency situations, can save a substantial amount of your investment portfolio, thereby
like big unexpected medical bills, money over time. Cash buyers may missing the opportunity to invest in
your car dies, you lose your job, etc. also have more negotiating power, as other assets that could increase your
On the other hand, if you lose your they are not reliant on bank approval wealth over time.
job and you have a mortgage, then and can close the deal quickly. In cer- Source: (Heming,2022)
you might end up defaulting on your tain situations, it can be better to bor- https://www.moneysupermarket.com/
loan, and lose the home and any of row money even if you have the cash. mortgages/advantages-and-
the equity you had in it. This is because investing the cash disadvantages/

into diversified investments (stocks,
bonds, etc. ) may provide better re-
turns than paying off the mortgage
early, although it comes with some
level of risk. Additionally, having
cash reserves can provide financial
flexibility for emergencies or future
opportunities.

Why can’t spam (human) Most of the spam call cen- (model) Spam call centers can’t be The example is not helpful in ad-
call centers be ters originate in countries where the automatically shut down because dressing the query. It is a contro-

References automatically shut governments don’t _really_ care all they are often located in coun- versial example that will stir up the
down? Additionally, that much. For example, a good tries with weak regulation and they emotions of readers, and therefore
why can’t spam calls number of them are in smaller cities use advanced techniques to hide distract them.
be automatically in India, where the politicians are their identity, like caller id spoof-
blocked, and why is willing to turn a blind eye for the ing. Blocking spam calls is challeng-
nobody really doing right price (and so long as they ing because these callers use ever-
a whole lot about it? don’t go around scamming Indians). changing phone numbers, making
It seems like this is From there, the call centers are just it difficult to maintain an updated
a problem that they another overseas call. There are a block list. While there are some
would have come up number of _legitimate_ call centers efforts to combat spam calls, such
with a solution for in foreign countries, so looking to as telecom companies implement-
by now. block the scam ones is a needle in a ing call-filtering systems and gov-

stack of needles. Its a ton of effort ernments enacting regulations, the
for the phone company with little issue is deeply rooted in the eco-
actual benefit to them. nomic incentive for spam callers and

the complexities in tracking them
down. Ultimately, tackling spam
calls requires international cooper-
ation and continuous technology ad-
vancements.

20466



Table 14: Examples of answers refined using our Error-informed Refinement approach. We show the feedback
from the error-feedback model and the corresponding refined answers from the refinement model incorporating the
feedback. The highlighted portion in the refined answer depicts the feedback incorporated in the answer.

Question Answer Feedback Refined Answer

[ELI5] Why do cars Reverse gears often are straight-cut in- Consistency score: 1.0 Cars can sound different in reverse due
sound different in re- stead of cross-cut because they get used Prediction: to the type of gears used in the transmis-
verse? far less and are cheaper to make.[...] 1. [Incomplete] Reasons: This is correct sion. Reverse gears are often straight-cut

The gears on the top are cross-cut and but could be improved by mentioning that instead of cross-cut because they are used
make far less noise and last a lot longer. straight-cut gears are louder because there less frequently and are therefore cheaper
Straight cut makes more noise because is more friction between the teeth when to manufacture. Straight-cut gears have
the teeth sort of slap against each other they meet. This causes more heat buildup teeth that meet end-to-end, causing more
as the gears mesh. Cross cut are quiet and wear on the teeth, which contributes friction and heat buildup, which results in
because the more gently mesh with each to the noise. [...] a louder noise. In contrast, cross-cut gears
other over a diagonal. 2. [Complete] have teeth that mesh at an angle, reducing

3. [Complete] the amount of friction and heat generated,
4. [Complete] resulting in a quieter noise. Additionally,
5. [Complete] straight-cut gears tend to have more play

between the teeth, which can also con-
tribute to the noise. To hear the difference
for yourself, you can listen to a video of
a car reversing with both straight-cut and
cross-cut gears.[...]

[ELI5] How have In liquid form? In a way, yeah. Usually in Consistency score: 1.0 To bring air inside the International Space
they brought air the form of water, which is safe to trans- Prediction: Station (ISS), the astronauts use a pro-
inside the Inter- port, doesn’t have to be pressurized and 1. [Incomplete] Reasons: The answer cess called öxygen generation,ẅhere they
national Space you only have to vent the excess hydro- does not completely describe how this is convert carbon dioxide and other gases
Station? In liquid gen. possible. It mentions that water is used as present in the space station’s atmosphere
form? a source of oxygen, but it fails to explain into breathable oxygen. This process in-

how this works. Additionally, it does not volves several steps:
address the issue of bringing air into the 1. Carbon Dioxide Removal: [...]
ISS from an external source. 2. Oxygen Generation: [...]
2. [Complete] 3. Air Revitalization: [...]
3. [Complete] 4. Humidification: [...]

5. Filtering: [...]
In terms of bringing air into the ISS from
an external source, there are actually two
methods used:
1. Atmospheric Replenishment: [...]
2. Cargo Vehicle Supply: [...]
So, to summarize, the ISS has systems
in place to generate oxygen from car-
bon dioxide and other gases present in
the space station’s atmosphere, as well as
methods for bringing in air from external
sources when necessary.

[ELI5] Why are Some busses and trains in Sweden actu- Consistency score: 1.0 Chairs are designed with a slight incline
chairs slightly in- ally have chairs that make you sit with a Prediction: rather than being perfectly straight for
curved instead of the straight back, but i think It’s cause people 1. [Incomplete] Reasons: The answer several reasons. Firstly, an angled seat
other way around? find those types of chairs more comfort- does not explain why most chairs are allows users to maintain better posture

able. slightly inclined. while sitting. When the backrest is at a
slight angle, it supports the natural curva-
ture of the spine, promoting good posture
and reducing strain on the back and neck
muscles. This can help prevent long-term
health issues associated with poor sitting
positions, such as lower back pain and
herniated discs.
Additionally, the inclination of the chair
helps to distribute weight evenly across
the seat and backrest, reducing pressure
points and providing a more comfortable
sitting experience. This is particularly im-
portant for people who spend extended pe-
riods of time sitting, such as office work-
ers or students.
While some buses and trains in Sweden
may have straight-backed seats, this de-
sign is not typical of most chairs found
in everyday use. In fact, many ergonomic
experts recommend that chairs be de-
signed with a slight incline to promote
proper posture and reduce discomfort.[...]

Continued on next page

20467



Question Answer Feedback Refined Answer

[ASQA] When did The first handheld cellular mobile phone Consistency score: 0.55 The first handheld cellular mobile phone
the first cellular was demonstrated by John F. Mitchell and Prediction: was demonstrated by John F. Mitchell and
phone come out? Martin Cooper of Motorola in 1973. In 1. [Incomplete] Reasons: This is correct Martin Cooper of Motorola in 1973. This

1983, the DynaTAC 8000x was the first but it would be useful to mention demonstration showcased the potential of
commercially available handheld mobile that this demonstration didn’t lead to a portable device that could communi-
phone. The phone had a talk time of the development of an actual product. cate wirelessly over long distances, revo-
just thirty minutes and took ten hours to Instead, it showed the potential of such a lutionizing the way people communicated
charge. device. while on-the-go. However, it wasn’t until

2. [Complete] 1983 that the first commercially available
3. [Complete] handheld mobile phone, the DynaTAC

8000x, became available to consumers.
With a talk time of just thirty minutes
and a charging time of ten hours, this
early model paved the way for future ad-
vancements in mobile technology. Today,
smartphones have become an essential
part of modern life, offering a wide range
of features and capabilities beyond sim-
ply making calls and sending texts.

[ASQA] Where is The Danube river is the second longest Consistency score: 0.70 The Danube River is the second longest
the danube river lo- river in Europe, running through Cen- Prediction: river in Europe, flowing through Central
cated in europe? tral and Eastern Europe. Starting in 1. [Complete] and Eastern Europe for a total length of

Germany the river flows through Aus- 2. [Complete] approximately 2,857 kilometers (1,777
tria, Slovakia, Hungary, Croatia, Ser- 3. [Incomplete] Reasons: These are just miles). It originates in the Black Forest
bia, Romania, Bulgaria, Moldova and names of cities; it would be useful to region of Germany, then passes through
Ukraine before draining into the Black know where they are located (which coun- or along the borders of several other Eu-
Sea. The river flows through many cities tries) so you can understand how the river ropean countries, including Austria, Slo-
including Pančevo, Drobeta-Turnu Sev- flows through different nations. vakia, Hungary, Croatia, Serbia, Roma-
erin, Bratislava, Ruse, Novi Sad, Ulm, nia, Bulgaria, Moldova, and Ukraine be-
Vienna, Zemun, Vidin, Regensburg, In- fore emptying into the Black Sea.
golstadt, Linz, Győr, Dunaújváros, Smed- Along its journey, the Danube River
erevo, Izmail, Belgrade, Apatin, Galat,i, flows through numerous cities and towns,
Vukovar and Budapest. some of which include:

* In Germany: Ulm, Ingolstadt, and
Regensburg * In Austria: Linz and
Vienna * In Slovakia: Bratislava * In
Hungary: Budapest, Gyor, and Szeged
* In Croatia: Vukovar and Osijek * In
Serbia: Belgrade and Smederevo * In
Romania: Bucharest and Galati * In
Bulgaria: Ruse and Vidin * In Moldova:
Kishinev * In Ukraine: Odessa and Reni

Each of these cities has a unique history
and culture, [...].

[HQ2A] How did Human trafficking became a thing likely Consistency score: 0.55 Human trafficking, unfortunately, has a
human trafficking in pre-history and hasn’t stopped at all. Prediction: long and complex history that dates back
become a thing? There is always a need for people to do 1. [Incomplete] Reasons: This is correct; to pre-historic times. The practice of cap-
Why do people something and being sent from one place it mentions that human trafficking has turing and enslaving individuals for vari-
kidnap and sell to another. Various forms of slavery is occurred since prehistoric times and ous purposes, including forced labor and
others? obviously a prominent activity and has continues today. However, it would be sexual exploitation, can be traced back

been present in many societies since pre- useful to trace the historical emergence to ancient civilizations such as Greece,
history and still exists today. of modern slave trade and human Rome, and Egypt. However, the mod-

trafficking. For example, it could explain ern form of human trafficking, which in-
how during the transatlantic slave trade, volves the use of force, fraud, or coercion
African slaves were transported across to exploit people for labor or commercial
the Atlantic Ocean to the Americas sex, gained momentum during the transat-
(https://www.britannica.com/topic/ lantic slave trade era.
transatlantic-slave-trade). This would During this period, millions of Africans
help to provide context and give further were forcibly taken from their homes and
insight into the history of human traffick- sold into slavery in the Americas, where
ing. they were subjected to brutal working
2. [Complete] conditions and treated as property rather
3. [Complete] than human beings. This tragic chapter

in human history laid the foundation for
the modern human trafficking industry,
which has evolved over time to include
a wide range of activities, such as child
labor, domestic servitude, [...]
So, why do people engage in human traf-
ficking? The reasons are complex and
varied, but some common motivations in-
clude financial gain, power and control,
and a lack of empathy for the victims.
Traffickers often target vulnerable indi-
viduals, such as those living in poverty
or fleeing conflict, and use manipulation,
coercion, and violence to keep them [...]

Continued on next page

20468



Question Answer Feedback Refined Answer

[HQ2A] How are e- E-fits, or electronic facial composites, Consistency score: 1.0 E-fits, or electronic facial composites,
fits constructed in are digital images created to help iden- Prediction: are digital images created to help iden-
the pursuit of a sus- tify suspects in criminal investigations. 1. [Complete] tify suspects in criminal investigations.
pect? They are constructed by combining dif- 2. [Complete] They are constructed by combining dif-

ferent facial features based on the eye- 3. [Complete] ferent facial features based on the eye-
witness’s description of the suspect. The 4. [Complete] witness’s description of the suspect. The
process starts with an interview between 5. [Complete] process starts with an interview between
the eyewitness and a trained police offi- 6. [Complete] the eyewitness and a trained police offi-
cer or forensic artist. The officer uses 7. [Complete] cer or forensic artist. The officer uses
specialized software, which contains a 8. [Incomplete] Reasons: It would be specialized software, which contains a
database of various facial features, such helpful if this section elaborated more on database of various facial features, such
as eyes, noses, mouths, and hairstyles. how e-fits are shared and why it is benefi- as eyes, noses, mouths, and hairstyles.
The eyewitness selects the features that cial to do so. The eyewitness selects the features that
best match their memory of the suspect’s best match their memory of the suspect’s
appearance. Once the initial facial com- appearance. Once the initial facial com-
posite is created, the officer and the eye- posite is created, the officer and the eye-
witness work together to refine the image. witness work together to refine the image.
They may adjust the size, shape, and posi- They may adjust the size, shape, and po-
tion of features to improve accuracy. The sition of features to improve accuracy.
final e-fit is then used to aid police investi- Once the e-fit is complete, it can be shared
gations, typically by sharing with the pub- with the public and other law enforcement
lic and other law enforcement agencies, agencies through various channels, such
in the hopes of identifying the suspect. as social media, local news outlets, and

online crime reporting platforms. Shar-
ing the e-fit helps to increase the chances
of identifying the suspect, as it allows a
larger pool of people to view and recog-
nize the individual. Additionally, sharing
the e-fit can also serve as a deterrent to
the suspect, as they may become aware
that the authorities are actively searching
for them.
In addition to being shared with the pub-
lic, e-fits can also be distributed to other
law enforcement agencies, such as federal
authorities, neighboring jurisdictions, and
international partners. This helps to ex-
pand the search area and increase the like-
lihood of identifying the suspect. Further-
more, e-fits can be updated and revised
as new information becomes available, al-
lowing the investigation to continue until
the suspect is apprehended. [...]

20469